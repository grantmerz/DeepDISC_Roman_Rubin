{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0e2d6b7-fb4a-48e4-b633-16029cb388cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yse2/deepdisc/src/deepdisc/__init__.py\n",
      "/home/yse2/detectron2/detectron2/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# In case you need to point to pre-existing scarlet install\n",
    "import sys\n",
    "# change these paths to your specific directories where deepdisc and detectron2 are stored\n",
    "sys.path.insert(0, '/home/yse2/deepdisc/src')\n",
    "sys.path.insert(0, '/home/yse2/detectron2')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# warnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning)\n",
    "# warnings.filterwarnings(\"ignore\", category=DtypeWarning)\n",
    "import deepdisc\n",
    "import detectron2\n",
    "print(deepdisc.__file__)\n",
    "print(detectron2.__file__)\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "# Standard imports\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import glob\n",
    "import scarlet\n",
    "import cv2\n",
    "import argparse\n",
    "# for multiprocessing\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "import psutil\n",
    "\n",
    "# astropy\n",
    "import astropy.io.fits as fits\n",
    "import astropy.units as u\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.table import Table\n",
    "from astropy.stats import gaussian_fwhm_to_sigma\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "\n",
    "# Astrodet imports\n",
    "from deepdisc.preprocessing.get_data import get_cutout\n",
    "from deepdisc.astrodet.hsc import get_tract_patch_from_coord, get_hsc_data\n",
    "from deepdisc.astrodet.visualizer import ColorMode\n",
    "from deepdisc.astrodet.visualizer import Visualizer\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "from galcheat.utilities import mag2counts, mean_sky_level\n",
    "from btk.survey import Filter, Survey, make_wcs\n",
    "import galsim\n",
    "import btk\n",
    "\n",
    "def e1e2_to_ephi(e1,e2):\n",
    "    \n",
    "    pa = np.arctan(e2/e1)\n",
    "    \n",
    "    return pa\n",
    "\n",
    "def get_wcs_dict_path(roman_file):\n",
    "    parts = roman_file.split('/')\n",
    "    subpatch = parts[-2]  #  dc2_51.37_-38.3\n",
    "    filename = parts[-1]  # full_c108_51.37_-38.3_centered_roman_9.npy\n",
    "    \n",
    "    cutout_num = filename.split('_')[1]  # c108\n",
    "    obj_id = filename.split('_')[-1].replace('.npy', '')  # 9\n",
    "    \n",
    "    wcs_path = f\"./trunc-lsst/metadata/{subpatch}/full_{cutout_num}_lsst_{obj_id}.json\"\n",
    "    \n",
    "    return wcs_path\n",
    "\n",
    "def dcut_reformat(obj_params):\n",
    "    \"\"\"Reformat object parameters for a single object\"\"\"\n",
    "    cat = pd.DataFrame([obj_params])  # Convert single object dict to DataFrame\n",
    "    L0 = 3.0128e28\n",
    "    for band in ['u', 'g', 'r', 'i', 'z', 'y']:\n",
    "        cat[f'{band}_ab'] = cat[f'mag_true_{band}']\n",
    "        total_flux = L0 * 10**(-0.4*cat[f'mag_true_{band}'])\n",
    "        bulge_to_total_ratio = cat[f'bulge_to_total_ratio_{band}']\n",
    "\n",
    "        cat[f'fluxnorm_bulge_{band}'] = total_flux * bulge_to_total_ratio\n",
    "        cat[f'fluxnorm_disk_{band}'] = total_flux * (1-bulge_to_total_ratio)\n",
    "        cat[f'fluxnorm_agn_{band}'] = np.zeros(total_flux.shape)\n",
    "\n",
    "    cat['a_b'] = cat['size_bulge_true']\n",
    "    cat['b_b'] = cat['size_minor_bulge_true']\n",
    "    cat['a_d'] = cat['size_disk_true']\n",
    "    cat['b_d'] = cat['size_minor_disk_true']\n",
    "    \n",
    "    cat['pa_bulge'] = e1e2_to_ephi(cat['ellipticity_1_bulge_true'],cat['ellipticity_2_bulge_true']) * 180.0/np.pi\n",
    "\n",
    "    cat['pa_disk'] = e1e2_to_ephi(cat['ellipticity_1_disk_true'],cat['ellipticity_2_disk_true']) * 180.0/np.pi\n",
    "    \n",
    "    cat['pa_tot'] = e1e2_to_ephi(cat['ellipticity_1_true'],cat['ellipticity_2_true']) * 180.0/np.pi\n",
    "\n",
    "    cat['g1'] = cat['shear_1']\n",
    "    cat['g2'] = cat['shear_2']\n",
    "    \n",
    "    return cat\n",
    "\n",
    "seed = 8312\n",
    "rng = np.random.RandomState(seed)\n",
    "grng = galsim.BaseDeviate(rng.randint(0, 2**30))\n",
    "\n",
    "def get_star_gsparams(mag, flux, noise):\n",
    "    \"\"\"\n",
    "    Get appropriate gsparams given flux and noise\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mag: float\n",
    "        mag of star\n",
    "    flux: float\n",
    "        flux of star\n",
    "    noise: float\n",
    "        noise of image\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    GSParams, isbright where isbright is true for stars with mag less than 18\n",
    "    \"\"\"\n",
    "    do_thresh = do_acc = False\n",
    "    if mag < 18:\n",
    "        do_thresh = True\n",
    "    if mag < 15:\n",
    "        do_acc = True\n",
    "\n",
    "    if do_thresh or do_acc:\n",
    "        isbright = True\n",
    "\n",
    "        kw = {}\n",
    "        if do_thresh:\n",
    "\n",
    "            # this is designed to quantize the folding_threshold values,\n",
    "            # so that there are fewer objects in the GalSim C++ cache.\n",
    "            # With continuous values of folding_threshold, there would be\n",
    "            # a moderately largish overhead for each object.\n",
    "\n",
    "            folding_threshold = noise/flux\n",
    "            folding_threshold = np.exp(\n",
    "                np.floor(np.log(folding_threshold))\n",
    "            )\n",
    "            kw['folding_threshold'] = min(folding_threshold, 0.005)\n",
    "\n",
    "        if do_acc:\n",
    "            kw['kvalue_accuracy'] = 1.0e-8\n",
    "            kw['maxk_threshold'] = 1.0e-5\n",
    "\n",
    "        gsparams = galsim.GSParams(**kw)\n",
    "    else:\n",
    "        gsparams = None\n",
    "        isbright = False\n",
    "\n",
    "    return gsparams, isbright\n",
    "\n",
    "def make_star(entry, survey, filt):\n",
    "    mag = entry[f'mag_{filt.name}'].iloc[0]\n",
    "    flux = mag2counts(mag, survey, filt).to_value(\"electron\")\n",
    "    noise = mean_sky_level(survey, filt).to_value('electron')\n",
    "    gsparams, isbright = get_star_gsparams(mag, flux, noise)\n",
    "    star = galsim.Gaussian(fwhm=1.0e-4, flux=flux, gsparams=gsparams)\n",
    "    return star, gsparams, flux\n",
    "\n",
    "def make_galaxy(entry, survey, filt, no_disk=False, no_bulge=False, no_agn=True):\n",
    "    \"\"\"Create galaxy object simulation - keeping original logic but for single object\"\"\"\n",
    "    components = []\n",
    "    total_flux = mag2counts(entry[filt.name + \"_ab\"].iloc[0], survey, filt).to_value(\"electron\")\n",
    "    \n",
    "    total_fluxnorm = (entry[\"fluxnorm_disk_\"+filt.name] + \n",
    "                      entry[\"fluxnorm_bulge_\"+filt.name] + \n",
    "                      entry[\"fluxnorm_agn_\"+filt.name]).iloc[0]\n",
    "    \n",
    "    disk_flux = 0.0 if no_disk else entry[\"fluxnorm_disk_\"+filt.name].iloc[0] / total_fluxnorm * total_flux\n",
    "    bulge_flux = 0.0 if no_bulge else entry[\"fluxnorm_bulge_\"+filt.name].iloc[0] / total_fluxnorm * total_flux\n",
    "    agn_flux = 0.0 if no_agn else entry[\"fluxnorm_agn_\"+filt.name].iloc[0]  / total_fluxnorm * total_flux\n",
    "    \n",
    "    if disk_flux + bulge_flux + agn_flux == 0:\n",
    "        raise ValueError(\"No visible components\")\n",
    "\n",
    "    if disk_flux > 0:\n",
    "        a_d, b_d = entry[\"a_d\"].iloc[0], entry[\"b_d\"].iloc[0]\n",
    "        disk_hlr_arcsecs = a_d\n",
    "        disk_q = b_d/a_d\n",
    "        pa = np.pi*entry['position_angle_true_dc2'].iloc[0]/180\n",
    "        \n",
    "        epsilon_disk = (1 - disk_q) / (1 + disk_q)\n",
    "        e1_disk = epsilon_disk * np.cos(2 * pa)\n",
    "        e2_disk = epsilon_disk * np.sin(2 * pa)\n",
    "\n",
    "        disk = galsim.Exponential(flux=disk_flux, half_light_radius=disk_hlr_arcsecs).shear(\n",
    "            e1=-e1_disk, e2=e2_disk\n",
    "        )\n",
    "        components.append(disk)\n",
    "        \n",
    "    if bulge_flux > 0:\n",
    "        a_b, b_b = entry[\"a_b\"].iloc[0], entry[\"b_b\"].iloc[0]\n",
    "        bulge_hlr_arcsecs = np.sqrt(a_b * b_b)\n",
    "        bulge_q = b_b/a_b\n",
    "        pa = np.pi*entry['position_angle_true_dc2'].iloc[0]/180\n",
    "        \n",
    "        epsilon_bulge = (1 - bulge_q) / (1 + bulge_q)\n",
    "        e1_bulge = epsilon_bulge * np.cos(2 * pa)\n",
    "        e2_bulge = epsilon_bulge * np.sin(2 * pa)\n",
    "        \n",
    "        bulge = galsim.DeVaucouleurs(flux=bulge_flux, half_light_radius=bulge_hlr_arcsecs).shear(\n",
    "           e1=-e1_bulge, e2=e2_bulge\n",
    "        )\n",
    "        components.append(bulge)\n",
    "    \n",
    "    if agn_flux > 0:\n",
    "        agn = galsim.Gaussian(flux=agn_flux, sigma=1e-8)\n",
    "        components.append(agn)\n",
    "\n",
    "    profile = galsim.Add(components)\n",
    "    return profile\n",
    "\n",
    "def make_im(entry, survey, filt, nx=128, ny=128):\n",
    "    \"\"\"Create image simulation for a single object\"\"\"\n",
    "    psf = survey.get_filter(filt).psf\n",
    "    obj_type = entry['truth_type'].iloc[0]\n",
    "    \n",
    "    if obj_type == 1:  # Galaxy\n",
    "        gal = make_galaxy(entry, survey, survey.get_filter(filt))\n",
    "        gal = gal.shear(g1=entry[\"g1\"].iloc[0], g2=entry[\"g2\"].iloc[0])\n",
    "        conv_gal = galsim.Convolve(gal, psf)\n",
    "        im = conv_gal.drawImage(\n",
    "            nx=nx,\n",
    "            ny=ny,\n",
    "            scale=survey.pixel_scale.to_value(\"arcsec\")\n",
    "        )\n",
    "    else:  # Star\n",
    "        star, gsparams, flux = make_star(entry, survey, survey.get_filter(filt))\n",
    "        max_n_photons = 10_000_000\n",
    "        # 0 means use the flux for n_photons \n",
    "        n_photons = 0 if flux < max_n_photons else max_n_photons\n",
    "        conv_star = galsim.Convolve(star, psf)\n",
    "        im = conv_star.drawImage(\n",
    "            nx=nx,\n",
    "            ny=ny,\n",
    "            scale=survey.pixel_scale.to_value(\"arcsec\"),\n",
    "            method=\"phot\",\n",
    "            n_photons=n_photons,\n",
    "            poisson_flux=True,\n",
    "            maxN=1_000_000,  # shoot in batches this size\n",
    "            rng=grng\n",
    "        )\n",
    "    return im\n",
    "\n",
    "def get_bbox(mask):\n",
    "    rows = np.any(mask, axis=1)\n",
    "    cols = np.any(mask, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    return rmin-4, rmax+4, cmin-4, cmax+4\n",
    "\n",
    "def create_single_object_metadata(obj_info, survey, filters, wcs_dict, lvl=2):\n",
    "    \"\"\"Create metadata for a single centered object\"\"\"\n",
    "    ddict = {\n",
    "        \"file_name\": \"./\" + wcs_dict[\"filename\"],\n",
    "        \"image_id\": obj_info[\"orig_image_id\"],\n",
    "        \"height\": 142,  # Assuming fixed size for centered cutouts\n",
    "        \"width\": 142,\n",
    "        \"subpatch\": obj_info[\"subpatch\"],\n",
    "        \"wcs\": wcs_dict['wcs']\n",
    "    }\n",
    "    \n",
    "    cat = dcut_reformat(obj_info[\"obj_params\"])\n",
    "    new_wcs = WCS(wcs_dict[\"wcs\"])\n",
    "    \n",
    "    ra = obj_info[\"ra\"]\n",
    "    dec = obj_info[\"dec\"]\n",
    "    new_x, new_y = new_wcs.world_to_pixel(SkyCoord(ra=ra*u.deg, dec=dec*u.deg))\n",
    "    \n",
    "    x = int(new_x)\n",
    "    y = int(new_y)\n",
    "    \n",
    "    segs = []\n",
    "    for filt in filters:\n",
    "        im = make_im(cat, survey, filt)\n",
    "        imd = np.expand_dims(np.expand_dims(im.array, 0), 0)\n",
    "        sky_level = mean_sky_level(survey, filt).to_value('electron') # gain = 1\n",
    "        segs.append(btk.metrics.utils.get_segmentation(imd, sky_level, sigma_noise=2))\n",
    "    \n",
    "    mask = np.clip(np.sum(segs, axis=0), a_min=0, a_max=1)[0][0]\n",
    "    if np.sum(mask)==0:\n",
    "        print(f\"Mask summed to zero. Object skipped! {ddict['file_name']}\")\n",
    "        return\n",
    "    # Get object bbox and segmentation\n",
    "    bbox = get_bbox(mask)\n",
    "    x0 = bbox[2]\n",
    "    x1 = bbox[3]\n",
    "    y0 = bbox[0]\n",
    "    y1 = bbox[1]\n",
    "    \n",
    "    w = x1 - x0\n",
    "    h = y1 - y0\n",
    "    \n",
    "    bbox = [x-w/2, y-h/2, w, h]\n",
    "    \n",
    "    redshift = cat['redshift']\n",
    "    \n",
    "    contours, _ = cv2.findContours(\n",
    "        mask.astype(np.uint8),\n",
    "        cv2.RETR_TREE,\n",
    "        cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    \n",
    "    segmentation = []\n",
    "    for contour in contours:\n",
    "        contour = contour.flatten()\n",
    "        if len(contour) > 4:\n",
    "            contour[::2] += (int(np.rint(x))-x0-w//2)\n",
    "            contour[1::2] += (int(np.rint(y))-y0-h//2)\n",
    "            segmentation.append(contour.tolist())\n",
    "    \n",
    "    if len(segmentation) == 0:\n",
    "        print(f\"No segm mask! Obj skipped! {ddict['file_name']}\")\n",
    "        return\n",
    "    \n",
    "    obj = {\n",
    "        \"obj_id\": obj_info[\"obj_id\"],\n",
    "        \"bbox\": bbox,\n",
    "        \"area\": w * h,\n",
    "        \"bbox_mode\": 1,\n",
    "        \"segmentation\": segmentation,\n",
    "        \"category_id\": 1 if obj_info[\"truth_type\"] == 2 else 0,\n",
    "        \"redshift\": redshift,\n",
    "        \"mag_i\": cat[\"mag_i\"]\n",
    "    }\n",
    "    \n",
    "    ddict[\"annotations\"] = [obj]\n",
    "    \n",
    "    return ddict\n",
    "\n",
    "def process_centered_objects(centered_objects_file):\n",
    "    \"\"\"Process all centered objects and create annotations\"\"\"\n",
    "   \n",
    "    with open(centered_objects_file, 'r') as f:\n",
    "        centered_objects = json.load(f)\n",
    "    \n",
    "    survey = btk.survey.get_surveys(\"LSST\")\n",
    "    filters = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "    \n",
    "    # Process each object\n",
    "    all_metadata = []\n",
    "    for obj_info in centered_objects:\n",
    "        wcs_dict_file = get_wcs_dict_path(obj_info[\"roman_file\"])\n",
    "        with open(wcs_dict_file, 'r') as f:\n",
    "            wcs_dict = json.load(f)\n",
    "        metadata = create_single_object_metadata(\n",
    "            obj_info,\n",
    "            survey,\n",
    "            filters,\n",
    "            wcs_dict\n",
    "        )\n",
    "        all_metadata.append(metadata)\n",
    "    \n",
    "    df = pd.DataFrame(all_metadata)\n",
    "#     output_file = f'/home/shared/hsc/roman_lsst/lsst_data/annotations/{sub_patch}.json'\n",
    "    output_file = f'test-centered.json'\n",
    "    df.to_json(output_file, orient='records')\n",
    "#     with open('test_centered.json', 'w') as f:\n",
    "#         json.dump(all_metadata, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c3018ea-04c2-4afe-8ecc-679330101d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_objects_file = \"cutout_processing_info_1.json\"  # Your truncated objects file\n",
    "wcs_dict_file = \"./trunc-lsst/metadata/dc2_51.37_-38.3/full_c108_lsst_1.json\"  # Your WCS dictionary file\n",
    "process_centered_objects(centered_objects_file, wcs_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f991cb85-1bad-4265-a124-f0de913bd8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_objects_file = \"cutout_processing_info_9.json\"  # Your truncated objects file\n",
    "wcs_dict_file = \"./trunc-lsst/metadata/dc2_51.37_-38.3/full_c108_lsst_9.json\"  # Your WCS dictionary file\n",
    "process_centered_objects(centered_objects_file, wcs_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32336b81-ee43-4944-90f1-b5759a38654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_objects_file = \"cutout_processing_info.json\"\n",
    "process_centered_objects(centered_objects_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac49db1-3e76-4869-af09-fd8e8f529b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-btknv]",
   "language": "python",
   "name": "conda-env-.conda-btknv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
