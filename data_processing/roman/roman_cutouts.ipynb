{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bae8b38-22cb-444d-b609-88d7b15a79af",
   "metadata": {
    "tags": []
   },
   "source": [
    "We will be using synthetic imaging survey data from the joint [Roman Space Telescope and Rubin Observatory simulation](https://academic.oup.com/mnras/article/522/2/2801/7076879) described in Troxel et al. (2023). The data consists of overlapping 20 deg^2 synthetic observations from the Nancy Grace Roman Space Telescope High-Latitude Imaging Survey (HLIS) and 5 years of the Vera C. Rubin Observatory Legacy Survey of Space and Time (LSST), both observing the same simulated [DESC DC2 universe](https://academic.oup.com/mnras/article/522/2/2801/7076879#sec2).\n",
    "\n",
    "# Available Data Products\n",
    "\n",
    "The dataset contains several FITS file types across multiple sky regions (tilenames are in the form of {RA}\\_{DEC}):\n",
    "\n",
    "- **Detection Catalogs** (`roman_data/detection_fits/dc2_det_{RA}_{Dec}.fits.gz`) - Source Extractor catalogs containing photometric measurements and coordinates (`alphawin_j2000`, `deltawin_j2000`) for objects detected in the Roman coadded images\n",
    "- **Segmentation Maps** (`roman_data/segmentation_fits/dc2_seg_{RA}_{Dec}.fits.gz`) - Pixel-level object identification maps where each detected object is assigned a unique int ID corresponding to entries in the detection catalog\n",
    "\n",
    "Both the object detection and segmentation is performed on a median detection image built from Y106, J129, H158, and F184 coadd images rather than taking the union of detections in each bandpass coadd. SExtractor run on this **median image** to create the segmentation map. Basic photometric information is provided for each bandpass coadd, with a 5$\\sigma$ model detection threshold based on the median image. \n",
    "\n",
    "This means that the segment IDs are consistent across all filters for each tile. The segmentation represents objects detected using the combined sensitivity of *all* Roman filters. Photometry is then measured on each individual filter's coadd using the positions/segments from the median detection.\n",
    "\n",
    "- **Truth Catalogs** (`roman_data/truth_fits/dc2_index_{RA}_{Dec}.fits.gz`) - Ground truth object properties including true positions (`ra`, `dec`), magnitudes, and physical params from the input [CosmoDC2 catalog](https://academic.oup.com/mnras/article/522/2/2801/7076879#sec2)\n",
    "- **Imaging Data** (`roman_data/original_fits/dc2_{F184|H158|J129|Y106}_{RA}_{Dec}.fits`) - Roman coadded images in four bands (F184,H158,J129,Y106)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c927b0e-f44e-4b01-ab7f-ddb07257b106",
   "metadata": {},
   "source": [
    "# Our Data Products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e865d7e6-be7a-4217-81cd-673e78b6af20",
   "metadata": {},
   "source": [
    "Our processing pipeline will transform the Troxel data into 512x512 cutouts and generate DeepDISC formatted annotations. We will be using randomly selected tiles from the imaging data. \n",
    "\n",
    "‚ö†Ô∏è **Critical Limitation**: Currently, our annotations represent only objects that were **both detected AND successfully matched to ground truth**, not the complete truth catalog. This introduces important selection effects that must be considered in analysis.\n",
    "\n",
    "## File Structure\n",
    "\n",
    "```\n",
    "roman_data/\n",
    "‚îú‚îÄ‚îÄ annotations/                         \n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 50.93_-42.0.json                 # COCO-format annotations per tile\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 51.34_-41.3.json\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îú‚îÄ‚îÄ truth/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ {RA}_{DEC}/                       # Per-tile processing results\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ full_{RA}_{DEC}.npy           # Multi-band coadded image\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ full_c{ID}_{RA}_{DEC}.npy     # 512√ó512 cutout images\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ matched_c{ID}_{RA}_{DEC}.json # Cross-matched objects\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ det_c{ID}_{RA}_{DEC}.json     # Detection catalog subsets\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ truth_c{ID}_{RA}_{DEC}.json   # Truth catalog subsets\n",
    "```\n",
    "\n",
    "## Description of Each Folder\n",
    "\n",
    "### 1. Annotations Folder (`./roman_data/annotations/`)\n",
    "\n",
    "**Purpose**: DeepDISC-ready object detection annotations in COCO format\n",
    "\n",
    "**File Format**: JSON files named `{RA}_{DEC}.json`\n",
    "\n",
    "**Content**: Each file contains annotations for all 225 cutouts within a sky tile. Sometimes, the annotations array may be empty indicating there are no detected objects that passed the selection criteria we have chosen above.\n",
    "\n",
    "#### Annotation Schema\n",
    "```json\n",
    "{\n",
    "  \"annotations\": [\n",
    "    {\n",
    "      \"bbox\": [x, y, width, height],           // Object bounding box\n",
    "      \"bbox_mode\": \"XYWH_ABS\",                 // Detectron2 format\n",
    "      \"segmentation\": [[x1,y1, x2,y2, ...]],  // Pixel-level contours\n",
    "      \"category_id\": 0,                        // 0=galaxy (extended sources), 1=star (point sources)\n",
    "      \"obj_id\": 142,                           // Segmentation map ID\n",
    "      \"area\": 234,                             // Pixel area\n",
    "      \n",
    "      // Photometric properties\n",
    "      \"mag_F184\": 23.45,                       // F184 band magnitude\n",
    "      \"mag_H158\": 23.12,                       // H158 band magnitude  \n",
    "      \"mag_J129\": 23.67,                       // J129 band magnitude\n",
    "      \"mag_Y106\": 23.89,                       // Y106 band magnitude\n",
    "      \n",
    "      \"ra\": 50.934567,                         // Right ascension (deg)\n",
    "      \"dec\": -42.012345,                       // Declination (deg)\n",
    "      \n",
    "      // Quality metrics\n",
    "      \"sep_arcsec\": 0.0234,                    // Detection-truth separation\n",
    "      \"n_competing_dets\": 1,                   // Number of competing detections\n",
    "      \"match_quality\": \"unique\"                // \"unique\" or \"closest_of_multiple\"\n",
    "    }\n",
    "  ],\n",
    "  \"image_id\": 123,                             // Cutout identifier\n",
    "  \"height\": 512,                              // Image height\n",
    "  \"width\": 512,                               // Image width\n",
    "  \"file_name\": \"./roman_data/truth/.../full_c123_50.93_-42.0.npy\"\n",
    "}\n",
    "```\n",
    "\n",
    "### 2. Image Data\n",
    "\n",
    "#### Multi-band Cutouts (`full_c{ID}_{RA}_{DEC}.npy`)\n",
    "- **Format**: NumPy arrays with shape `(4, 512, 512)`\n",
    "- **Bands**: [F184, H158, Y106, J129] - Roman Space Telescope near-infrared filters\n",
    "- **Pixel Scale**: 0.0575 arcsec/pixel (Roman coadd resolution)\n",
    "- **Coverage**: 512√ó512 pixel cutouts from larger survey tiles. Only using the core region avoiding 500px overlap on each edge\n",
    "\n",
    "#### Full Tile Images (`full_{RA}_{DEC}.npy`)\n",
    "- **Format**: NumPy arrays with shape `(4, 8825, 8825)`\n",
    "- **Purpose**: Complete multi-band coadds for each processed sky tile\n",
    "\n",
    "### 3. Catalog Data\n",
    "\n",
    "#### Cross-matched Objects (`matched_c{ID}_{RA}_{DEC}.json`)\n",
    "- **Content**: Detection-truth pairs with quality metrics (sep distance) and all underlying truth catalog information\n",
    "- Quality assessment and filtering of training data\n",
    "\n",
    "#### Detection Catalogs (`det_c{ID}_{RA}_{DEC}.json`)\n",
    "- Subset of detection catalog for each cutout and derived from segmentation map object identification and further filtered within cutout boundaries\n",
    "\n",
    "#### Truth Catalogs (`truth_c{ID}_{RA}_{DEC}.json`)\n",
    "- Subset of truth catalog within cutout boundaries so objects with centroids inside 512√ó512 cutout area\n",
    "\n",
    "In total, **35.99 GB** of data created.\n",
    "\n",
    "## Dataset Stats\n",
    "\n",
    "### Coverage\n",
    "- **Sky Area**: ~ \\<TO BE CALCULATED\\> deg^2 total across 16 processed tiles\n",
    "- **Cutouts**: ~3,600 total (225 per tile)\n",
    "- **Wavelength Range**: 0.93-2.00 $\\mu$m from https://roman.gsfc.nasa.gov/images/pdf/Roman-Instruments-Chart.pdf\n",
    "\n",
    "### Object Counts (Over all 16 tiles)\n",
    "| Category | Count | Notes |\n",
    "|----------|-------|-------|\n",
    "| Truth objects | ~30k-35k | Complete ground truth catalog |\n",
    "| Detected objects | ~18k-25k | Successfully detected sources |\n",
    "| Annotated objects | <TO BE CALCULATED\\> | Detection-truth matches (our annotations) |\n",
    "| Annotation completeness | **~ <TO BE CALCULATED\\> ~** | **Fraction of truth objects with annotations** |\n",
    "\n",
    "\n",
    "### Cross-matching Methodology\n",
    "- **Tolerance**: 0.0575 arcsec (1 Roman pixel) maximum separation\n",
    "- **Closest-match selection** for multiple detection candidates\n",
    "- **Match Reliability**: _ % \"unique\" matches, _ % \"closest_of_multiple\"\n",
    "- **Spatial Accuracy**: Median detection-truth separation _ arcsec\n",
    "\n",
    "### Timing\n",
    "Takes 7.2 minutes with parallel processing (64 CPUs) to do all 16 tiles. \n",
    "\n",
    "### Current Limitations\n",
    "\n",
    "1. **Incomplete Ground Truth**: Only _ of truth objects are annotated\n",
    "3. **Missing Morphology**: No morphological parameters for shape modeling\n",
    "4. **Detection Dependency**: Annotations limited by detection algorithm performance\n",
    "\n",
    "### Future Improvements\n",
    "\n",
    "1. **Truth-based Annotations**: Extract morphological parameters from sims\n",
    "2. **Negative Sampling**: Add background/artifact annotations for complete training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b0fed-7df8-4e83-9b58-d85f7fcae0d3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f56d5e7-ca21-48c4-b8e0-2550581da2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yse2/.conda/envs/deepdisc/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re, os, cv2, time, gc\n",
    "import warnings\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from urllib.parse import urljoin\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.table import Table\n",
    "from astropy.wcs import WCS\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "from detectron2.structures import BoxMode\n",
    "from deepdisc.data_format.conversions import convert_to_json\n",
    "\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0bdd2c-da42-4f0d-a2af-529894edbb1e",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde98986-57db-468c-b411-1de8143239db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ra_dec(filename):\n",
    "    matches = re.search(r'dc2_(det|seg|index)_(\\d+\\.\\d+)_(\\-\\d+\\.\\d+)', filename)\n",
    "    if matches:\n",
    "        return matches.group(2), matches.group(3)\n",
    "    return None\n",
    "\n",
    "def create_multiband_coadd(ra_dec):\n",
    "    target_file = f\"roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/full_{ra_dec[0]}_{ra_dec[1]}.npy\"\n",
    "    # we still load in f184_img so we can grab the wcs\n",
    "    f184_img = fits.open(f'roman_data/original_fits/{ra_dec[0]}_{ra_dec[1]}/F184_{ra_dec[0]}_{ra_dec[1]}.fits')\n",
    "    w = WCS(f184_img[1].header)\n",
    "    if os.path.exists(target_file):\n",
    "        print(f\"Multiband coadd for {ra_dec[0]}_{ra_dec[1]} has already been created!\")\n",
    "        full_img_data = np.load(target_file)\n",
    "        return full_img_data, w\n",
    "    h158_img = fits.open(f'roman_data/original_fits/{ra_dec[0]}_{ra_dec[1]}/H158_{ra_dec[0]}_{ra_dec[1]}.fits')\n",
    "    y106_img = fits.open(f'roman_data/original_fits/{ra_dec[0]}_{ra_dec[1]}/Y106_{ra_dec[0]}_{ra_dec[1]}.fits')\n",
    "    j129_img = fits.open(f'roman_data/original_fits/{ra_dec[0]}_{ra_dec[1]}/J129_{ra_dec[0]}_{ra_dec[1]}.fits')\n",
    "    full_img_data = np.stack((f184_img[1].data, h158_img[1].data, y106_img[1].data, j129_img[1].data))\n",
    "    np.save(target_file, full_img_data)\n",
    "    \n",
    "    f184_img.close()\n",
    "    h158_img.close()\n",
    "    y106_img.close()\n",
    "    j129_img.close()\n",
    "    \n",
    "    print(f\"Multiband coadd saved to {target_file}\")\n",
    "    return full_img_data, w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c038200-707e-4a7e-b852-aa6a1f99b77d",
   "metadata": {},
   "source": [
    "# Create Cutouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c633487a-4e71-48a3-b6c0-9ea222cd66c7",
   "metadata": {},
   "source": [
    "We will divide each 8825√ó8825 coadd into 512x512 cutouts for each filter and stack them into a four-channel coadd. We decided to only use the core region avoiding the 500px overlap on each edge from adjacent coadd tiles. When we attempted using the entire image or even the core region while allowing cutouts to extend into overlap regions, we ran into issues where the truth catalog for the given tilename didn't contain all the objects within each cutout.\n",
    "\n",
    "- **Image size:** 8825x8825\n",
    "- **Usable region**: 7825x7825 (starting at 500,500)\n",
    "- Cutouts: 15x15 = **225 total**\n",
    "- **Spacing:** x=522, y=522"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492f287b-fcb9-4747-929c-2fe37b0a0265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cutouts(seg_file, full_img_data, ra_dec, w):\n",
    "    seg = fits.open(seg_file)\n",
    "    cutout_size = 512\n",
    "    overlap_pixels = 500\n",
    "    coadd_size = seg[0].data.shape\n",
    "    # only use the core region avoiding 500px overlap on each edge\n",
    "    usable_width = coadd_size[1] - 2 * overlap_pixels  # 7825\n",
    "    usable_height = coadd_size[0] - 2 * overlap_pixels  # 7825\n",
    "    start_x, start_y = overlap_pixels, overlap_pixels  # 500, 500\n",
    "    \n",
    "    nx_cutouts = usable_width // cutout_size\n",
    "    ny_cutouts = usable_height // cutout_size\n",
    "        \n",
    "    # calc spacing to distribute cutouts evenly\n",
    "    if nx_cutouts > 1:\n",
    "        x_spacing = (usable_width - cutout_size) // (nx_cutouts - 1)\n",
    "    else:\n",
    "        x_spacing = 0\n",
    "\n",
    "    if ny_cutouts > 1:\n",
    "        y_spacing = (usable_height - cutout_size) // (ny_cutouts - 1)\n",
    "    else:\n",
    "        y_spacing = 0\n",
    "    \n",
    "    print(f\"Creating cutouts for {ra_dec[0]}_{ra_dec[1]}...\")\n",
    "    print(f\"Image size: {coadd_size[1]}x{coadd_size[0]}\")\n",
    "    print(f\"Usable region: {usable_width}x{usable_height} (starting at {start_x},{start_y})\")\n",
    "    print(f\"Cutouts: {nx_cutouts}x{ny_cutouts} = {nx_cutouts * ny_cutouts} total\")\n",
    "    print(f\"Spacing: x={x_spacing}, y={y_spacing}\")\n",
    "    roman_data/original_fits/52.40_-41.1/F184_52.40_-41.1.fits\n",
    "    roman_data/original_fits/52.40_-41.1/F184_52.40_-41.1.fits\n",
    "    counter = 0\n",
    "    seg_cutouts = []\n",
    "    for i in range(ny_cutouts):\n",
    "        for j in range(nx_cutouts):\n",
    "           # cutout center pos\n",
    "            if ny_cutouts == 1:\n",
    "                y_center = start_y + cutout_size // 2\n",
    "            else:\n",
    "                y_center = start_y + cutout_size // 2 + i * y_spacing\n",
    "            \n",
    "            if nx_cutouts == 1:\n",
    "                x_center = start_x + cutout_size // 2\n",
    "            else:\n",
    "                x_center = start_x + cutout_size // 2 + j * x_spacing\n",
    "            \n",
    "            seg_cutout = Cutout2D(seg[0].data, position=(x_center, y_center), \n",
    "                                size=cutout_size, wcs=w, mode='partial', fill_value=0)\n",
    "            seg_cutouts.append(seg_cutout)\n",
    "            \n",
    "            full_cutout_path = f'roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/full_c{counter}_{ra_dec[0]}_{ra_dec[1]}.npy'\n",
    "            if not os.path.exists(full_cutout_path):\n",
    "                raw_cutout_f184 = Cutout2D(full_img_data[0], position=(x_center, y_center), \n",
    "                                         size=cutout_size, wcs=w, mode='partial', fill_value=0)\n",
    "                raw_cutout_h158 = Cutout2D(full_img_data[1], position=(x_center, y_center), \n",
    "                                         size=cutout_size, wcs=w, mode='partial', fill_value=0)\n",
    "                raw_cutout_y106 = Cutout2D(full_img_data[2], position=(x_center, y_center), \n",
    "                                         size=cutout_size, wcs=w, mode='partial', fill_value=0)\n",
    "                raw_cutout_j129 = Cutout2D(full_img_data[3], position=(x_center, y_center), \n",
    "                                         size=cutout_size, wcs=w, mode='partial', fill_value=0)\n",
    "                full_raw_cutout = np.stack((raw_cutout_f184.data, raw_cutout_h158.data, \n",
    "                                          raw_cutout_y106.data, raw_cutout_j129.data)) \n",
    "                np.save(full_cutout_path, full_raw_cutout)\n",
    "            \n",
    "            # debug info for first few cutouts\n",
    "            if counter < 3:\n",
    "                print(f\"  Cutout {counter}: center=({x_center}, {y_center}), \"\n",
    "                      f\"bbox=({x_center-cutout_size//2}, {y_center-cutout_size//2}, \"\n",
    "                      f\"{x_center+cutout_size//2}, {y_center+cutout_size//2})\")\n",
    "            \n",
    "            counter += 1\n",
    "    seg.close()\n",
    "    print(f\"Created {len(seg_cutouts)} cutouts\")\n",
    "    return seg_cutouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e6e2d-7e1c-4b64-b452-b7caf12cf55b",
   "metadata": {},
   "source": [
    "\n",
    "Using each cutout's WCS, we will also extract all the detected objects (from segmentation maps) and truth objects (from input catalogs) within each cutout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d96f926-d4e2-4bf2-b10b-f5aa6a23e837",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extract Truth Objects from Truth Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714f38e0-006a-46e2-9405-4c29a2c743af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cutout_truth_cat(seg_cutouts, truth_df, ra_dec, verbose=False):\n",
    "    \"\"\"\n",
    "    We obtain a subset of the truth catalog for each cutout by first converting the 4 corners of the 512x512 cutout to RAs/DECs and then\n",
    "    filtering the truth catalog to only objects within those RA/Dec ranges. For convience, we also convert the filtered objects' coordinates \n",
    "    to cutout pixel coords.    \n",
    "    \"\"\"\n",
    "    truth_coords = SkyCoord(ra=truth_df['ra'].values*u.degree, dec=truth_df['dec'].values*u.degree)\n",
    "    truth_ras = truth_coords.ra.degree\n",
    "    truth_decs = truth_coords.dec.degree\n",
    "    # 4 corners of the 512x512 cutout\n",
    "    corners_pix = np.array([\n",
    "        [0, 0],        # bottom left\n",
    "        [511, 0],      # bottom right  \n",
    "        [511, 511],    # top right\n",
    "        [0, 511]       # top left\n",
    "    ])\n",
    "    \n",
    "    cutout_truth_filenames = []\n",
    "    cutout_truths = []\n",
    "\n",
    "    for imgid, seg_cutout in enumerate(seg_cutouts):\n",
    "        truth_cutout_path = f'roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/truth_c{imgid}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "        if not os.path.exists(truth_cutout_path):\n",
    "            corners_world = seg_cutout.wcs.pixel_to_world(corners_pix[:, 0], corners_pix[:, 1])\n",
    "            corner_ras = [coord.ra.degree for coord in corners_world]\n",
    "            corner_decs = [coord.dec.degree for coord in corners_world]\n",
    "            ra_min = min(corner_ras)\n",
    "            ra_max = max(corner_ras)\n",
    "            dec_min = min(corner_decs)\n",
    "            dec_max = max(corner_decs)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Cutout {imgid} boundaries:\")\n",
    "                print(f\"  RA: {ra_min:.6f}¬∞ to {ra_max:.6f}¬∞ (span: {(ra_max-ra_min)*3600:.2f}\\\")\")\n",
    "                print(f\"  Dec: {dec_min:.6f}¬∞ to {dec_max:.6f}¬∞ (span: {(dec_max-dec_min)*3600:.2f}\\\")\")\n",
    "                break\n",
    "\n",
    "            ra_mask = (truth_ras >= ra_min) & (truth_ras <= ra_max)\n",
    "            dec_mask = (truth_decs >= dec_min) & (truth_decs <= dec_max)\n",
    "            within_bounds = ra_mask & dec_mask\n",
    "            if not np.any(within_bounds):\n",
    "                print(f\"No truth objects found within cutout {imgid}\")\n",
    "                continue\n",
    "            cutout_truth = truth_df[within_bounds].copy()\n",
    "\n",
    "            cutout_truth_coords = truth_coords[within_bounds]\n",
    "            pix_coords = seg_cutout.wcs.world_to_pixel(cutout_truth_coords)\n",
    "            cutout_truth['cutout_x'] = pix_coords[0]\n",
    "            cutout_truth['cutout_y'] = pix_coords[1]\n",
    "            cutout_truth['cutout_id'] = imgid\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"  Found {len(cutout_truth)} truth objects within cutout {imgid} boundaries\")\n",
    "                print(f\"  Pixel coordinate ranges:\")\n",
    "                print(f\"    X: {cutout_truth['cutout_x'].min():.2f} to {cutout_truth['cutout_x'].max():.2f}\")\n",
    "                print(f\"    Y: {cutout_truth['cutout_y'].min():.2f} to {cutout_truth['cutout_y'].max():.2f}\")\n",
    "                break\n",
    "            \n",
    "            cutout_truth.to_json(truth_cutout_path, orient='records')\n",
    "        else:\n",
    "            cutout_truth = pd.read_json(truth_cutout_path)\n",
    "        \n",
    "        cutout_truth_filenames.append(truth_cutout_path)\n",
    "        cutout_truths.append(cutout_truth)\n",
    "        # break\n",
    "    \n",
    "    total_objects = sum(len(result) for result in cutout_truths)\n",
    "    non_empty_cutouts = sum(1 for result in cutout_truths if len(result) > 0)\n",
    "\n",
    "    print(f\"Completed truth catalog processing for {len(seg_cutouts)} cutouts\")\n",
    "    print(f\"  Total truth objects assigned: {total_objects}\")\n",
    "    print(f\"  Non-empty cutouts: {non_empty_cutouts}\")\n",
    "    print(f\"  Avg num of truth objects per non-empty cutout: {total_objects/non_empty_cutouts if non_empty_cutouts > 0 else 0:.1f}\")\n",
    "   \n",
    "    return cutout_truth_filenames, cutout_truths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9bbff7-1f56-4060-b4a5-4b18ef26ea99",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extract Detected Objs from Detection Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58380952-2712-4c51-a457-7c894c743e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cutout_det_cat(seg_cutouts, det_df, ra_dec, verbose=False):\n",
    "    \"\"\"\n",
    "    We obtain a subset of the det catalog for each cutout from the segmentation map and indexing into the detection catalog with those ids\n",
    "    For convience, we also convert the det objects' coords to cutout pixel coords.\n",
    "    \"\"\"\n",
    "    cutout_det_filenames = []\n",
    "    cutout_dets = []\n",
    "    corners_pix = np.array([\n",
    "        [0, 0],        # bottom left\n",
    "        [511, 0],      # bottom right  \n",
    "        [511, 511],    # top right\n",
    "        [0, 511]       # top left\n",
    "    ])\n",
    "    for imgid, seg_cutout in enumerate(seg_cutouts):\n",
    "        det_cutout_path = f'roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/det_c{imgid}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "        if not os.path.exists(det_cutout_path):\n",
    "            # unique objs from segm cutout\n",
    "            seg_objs = []\n",
    "            seg_img_cut = seg_cutout.data\n",
    "            for s in np.unique(seg_img_cut):\n",
    "                if s == 0:  # background\n",
    "                    continue\n",
    "                seg_objs.append(s)\n",
    "            seg_objs = np.asarray(seg_objs)\n",
    "\n",
    "            if len(seg_objs) == 0:\n",
    "                print(f\"No detected objects in this cutout {imgid}\")\n",
    "                continue\n",
    "\n",
    "            det_objs = det_df.iloc[seg_objs-1].copy()  # -1 because segmentation IDs are 1-indexed and we match to number col in det df\n",
    "            det_coords = SkyCoord(ra=det_objs['alphawin_j2000'].values*u.degree, \n",
    "                                 dec=det_objs['deltawin_j2000'].values*u.degree)\n",
    "            det_ras = det_coords.ra.degree\n",
    "            det_decs = det_coords.dec.degree\n",
    "            \n",
    "            # now we further filter the det coords by ensuring that we only take the objects whose center ra/dec is within the cutout\n",
    "            # some objs are detected in the segmentation map but their center ra/dec is outside of the cutout so we choose to exclude\n",
    "            # these objects despite there being a mask for them since we want to stay consistent with the filtering for truth catalog\n",
    "            corners_world = seg_cutout.wcs.pixel_to_world(corners_pix[:, 0], corners_pix[:, 1])\n",
    "            corner_ras = [coord.ra.degree for coord in corners_world]\n",
    "            corner_decs = [coord.dec.degree for coord in corners_world]\n",
    "            ra_min = min(corner_ras)\n",
    "            ra_max = max(corner_ras)\n",
    "            dec_min = min(corner_decs)\n",
    "            dec_max = max(corner_decs)\n",
    "            \n",
    "            ra_mask = (det_ras >= ra_min) & (det_ras <= ra_max)\n",
    "            dec_mask = (det_decs >= dec_min) & (det_decs <= dec_max)\n",
    "            within_bounds = ra_mask & dec_mask\n",
    "            if not np.any(within_bounds):\n",
    "                print(f\"No det objects found within cutout {imgid} after filtering by cutout boundaries\")\n",
    "                continue\n",
    "            cutout_det = det_objs[within_bounds].copy()\n",
    "            \n",
    "            cutout_det_coords = det_coords[within_bounds]\n",
    "            cutout_seg_objs = seg_objs[within_bounds]\n",
    "            pix_coords = seg_cutout.wcs.world_to_pixel(cutout_det_coords)\n",
    "            cutout_det['cutout_x'] = pix_coords[0]\n",
    "            cutout_det['cutout_y'] = pix_coords[1]\n",
    "            cutout_det['seg_id'] = cutout_seg_objs\n",
    "            cutout_det['cutout_id'] = imgid\n",
    "            \n",
    "            cutout_det.to_json(det_cutout_path, orient='records')\n",
    "        else:\n",
    "            cutout_det = pd.read_json(det_cutout_path)\n",
    "            \n",
    "        cutout_det_filenames.append(det_cutout_path)\n",
    "        cutout_dets.append(cutout_det)\n",
    "#         break\n",
    "    total_objects = sum(len(result) for result in cutout_dets)\n",
    "    non_empty_cutouts = sum(1 for result in cutout_dets if len(result) > 0)\n",
    "    \n",
    "    print(f\"Completed det catalog processing for {len(seg_cutouts)} cutouts\")\n",
    "    print(f\"  Total det objects assigned: {total_objects}\")\n",
    "    print(f\"  Non-empty cutouts: {non_empty_cutouts}\")\n",
    "    print(f\"  Avg num of det objects per non-empty cutout: {total_objects/non_empty_cutouts if non_empty_cutouts > 0 else 0:.1f}\")\n",
    "    return cutout_det_filenames, cutout_dets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd46c5d-3fcf-4550-84d5-2b147e29be2f",
   "metadata": {},
   "source": [
    "## Cross Match Detections to Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28d735e0-f72f-4f0b-a58a-ed84f38c2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_match_objects(det_df, truth_df, max_sep_arcsec=0.0575):\n",
    "    \"\"\"\n",
    "    Cross-match detection catalog and truth catalog for a cutout\n",
    "    \"\"\"\n",
    "    det_coords_np = np.column_stack([det_df['alphawin_j2000'].values, \n",
    "                                 det_df['deltawin_j2000'].values])\n",
    "    truth_coords_np = np.column_stack([truth_df['ra'].values, \n",
    "                                   truth_df['dec'].values])\n",
    "    # vectorized coord creation\n",
    "    det_coords = SkyCoord(ra=det_coords_np[:, 0]*u.degree, \n",
    "                            dec=det_coords_np[:, 1]*u.degree)\n",
    "    truth_coords = SkyCoord(ra=truth_coords_np[:, 0]*u.degree, \n",
    "                              dec=truth_coords_np[:, 1]*u.degree)\n",
    "    \n",
    "    # 0.0575 same as coadd pixel scale from https://academic.oup.com/mnras/article/522/2/2801/7076879?login=false\n",
    "    max_sep = max_sep_arcsec * u.arcsec\n",
    "    idx_truth, d2d, d3d = det_coords.match_to_catalog_sky(truth_coords)\n",
    "    sep_constraint = d2d <= max_sep\n",
    "    \n",
    "    matched_objs = pd.DataFrame()\n",
    "    seg_truth_mapping = {}\n",
    "    \n",
    "    if np.any(sep_constraint):\n",
    "        matched_det_idxs = np.where(sep_constraint)[0]\n",
    "        matched_truth_idxs = idx_truth[sep_constraint]\n",
    "        matched_seps = d2d[sep_constraint]\n",
    "        \n",
    "        unique_truth_idxs, counts = np.unique(matched_truth_idxs, return_counts=True)\n",
    "        \n",
    "        duplicate_truth_idxs = unique_truth_idxs[counts > 1]\n",
    "        \n",
    "        if len(duplicate_truth_idxs) > 0:\n",
    "            print(f\"Found {len(duplicate_truth_idxs)} truth objects matched by multiple detections:\")\n",
    "            for truth_idx in duplicate_truth_idxs:\n",
    "                det_matches = matched_det_idxs[matched_truth_idxs == truth_idx]\n",
    "                seps = matched_seps[matched_truth_idxs == truth_idx]\n",
    "                print(f\"  Truth index {truth_idx}: matched by {len(det_matches)} detections\")\n",
    "                for i, sep in enumerate(seps.to(u.arcsec).value):\n",
    "                    print(f\" Separation for det {det_matches[i]} : {sep:.4f} arcsec\")\n",
    "        \n",
    "        final_det_idxs = []\n",
    "        final_truth_idxs = []\n",
    "        final_seps = []\n",
    "        n_competing_dets = []\n",
    "        match_quality_flags = []\n",
    "    \n",
    "        for truth_idx in unique_truth_idxs:\n",
    "            # all dets matching this truth obj\n",
    "            matching_det_mask = matched_truth_idxs == truth_idx\n",
    "            matching_det_idxs = matched_det_idxs[matching_det_mask]\n",
    "            matching_seps = matched_seps[matching_det_mask]\n",
    "            # how many dets competed for this truth obj\n",
    "            n_competitors = len(matching_det_idxs)\n",
    "\n",
    "            # keeping closest match\n",
    "            closest_idx = np.argmin(matching_seps)\n",
    "            chosen_det_idx = matching_det_idxs[closest_idx]\n",
    "            chosen_sep = matching_seps[closest_idx]\n",
    "\n",
    "            final_det_idxs.append(chosen_det_idx)\n",
    "            final_truth_idxs.append(truth_idx)\n",
    "            final_seps.append(chosen_sep.to(u.arcsec).value)\n",
    "            n_competing_dets.append(n_competitors)\n",
    "            if n_competitors == 1:\n",
    "                match_quality_flags.append('unique')\n",
    "            else:\n",
    "                match_quality_flags.append('closest_of_multiple')\n",
    "        \n",
    "        final_det_idxs = np.array(final_det_idxs)\n",
    "        final_truth_idxs = np.array(final_truth_idxs)\n",
    "        final_seps = np.array(final_seps)\n",
    "        n_competing_dets = np.array(n_competing_dets) \n",
    "        \n",
    "        matched_dets = det_df.iloc[final_det_idxs].copy().reset_index(drop=True)\n",
    "        matched_truths = truth_df.iloc[final_truth_idxs].copy().reset_index(drop=True)\n",
    "        \n",
    "        matched_objs = matched_dets.copy()\n",
    "        for col in matched_truths.columns:\n",
    "            if col not in ['cutout_id', 'cutout_x', 'cutout_y']:\n",
    "                matched_objs[f'{col}'] = matched_truths[col].values\n",
    "            elif col in ['cutout_x', 'cutout_y']:\n",
    "                matched_objs[f'truth_{col}'] = matched_truths[col].values\n",
    "            \n",
    "        matched_objs['sep_arcsec'] = [sep for sep in final_seps]\n",
    "        matched_objs['sep_pixels'] = matched_objs['sep_arcsec'] / 0.0575  # roman pixel scale\n",
    "        matched_objs['n_competing_dets'] = n_competing_dets\n",
    "        matched_objs['is_ambiguous_match'] = n_competing_dets > 1\n",
    "        matched_objs['match_quality'] = match_quality_flags\n",
    "        \n",
    "        # mapping seg ID to truth classification and other truth info\n",
    "        for i, (det_idx, truth_idx) in enumerate(zip(final_det_idxs, final_truth_idxs)):\n",
    "            seg_id = det_df.iloc[det_idx]['seg_id']\n",
    "            truth_row = truth_df.iloc[truth_idx]\n",
    "            seg_truth_mapping[seg_id] = (int(truth_row['gal_star']), {\n",
    "                \"mag_F184\": truth_row['mag_F184'],\n",
    "                \"mag_H158\": truth_row['mag_H158'],\n",
    "                \"mag_J129\": truth_row['mag_J129'],\n",
    "                \"mag_Y106\": truth_row['mag_Y106'],\n",
    "                \"ra\": truth_row['ra'],\n",
    "                \"dec\": truth_row['dec'],\n",
    "                \"sep_arcsec\": final_seps[i],\n",
    "                \"n_competing_dets\": int(n_competing_dets[i]),\n",
    "                \"match_quality\": match_quality_flags[i]\n",
    "            })\n",
    "    \n",
    "    n_unique = np.sum(np.array(match_quality_flags) == 'unique')\n",
    "    n_ambiguous = np.sum(np.array(match_quality_flags) == 'closest_of_multiple')\n",
    "    median_sep = np.median([sep for sep in final_seps])\n",
    "\n",
    "#     print(f\"Match quality summary:\")\n",
    "#     print(f\"  Unique matches: {n_unique}\")\n",
    "#     print(f\"  Ambiguous matches (closest selected): {n_ambiguous}\")\n",
    "#     print(f\"  Median separation: {median_sep:.4f} arcsec\")\n",
    "#     print(f\"  Max competing detections for single truth: {np.max(n_competing_dets)}\")\n",
    "    \n",
    "    return matched_objs, seg_truth_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa33d21a-67ea-485b-9e4c-e5460c7adb42",
   "metadata": {},
   "source": [
    "# Create Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc3e2b-f641-4949-a684-8caff3beb5b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_metadata(seg_cutout_data, cutout_id, seg_truth_mapping):\n",
    "#     \"\"\"\n",
    "#     create metadata in the correct format for DeepDisc with annotations for matched detected objs in cutout\n",
    "#     \"\"\"\n",
    "#     anns = []\n",
    "#     for s in np.unique(seg_cutout_data):\n",
    "#         if s == 0:  # background\n",
    "#             continue   \n",
    "#         # mask for this object\n",
    "#         mask = np.zeros(seg_cutout_data.shape, dtype=np.uint8)\n",
    "#         s0i = np.where(seg_cutout_data == s)\n",
    "#         mask[s0i] = 1\n",
    "        \n",
    "#         x0 = s0i[1].min()\n",
    "#         x1 = s0i[1].max()\n",
    "#         y0 = s0i[0].min()\n",
    "#         y1 = s0i[0].max()\n",
    "        \n",
    "#         h = int(y1 - y0)\n",
    "#         w = int(x1 - x0)\n",
    "        \n",
    "#         contours, hierarchy = cv2.findContours(\n",
    "#             mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n",
    "#         )\n",
    "        \n",
    "#         segmentation = []\n",
    "#         for contour in contours:\n",
    "#             # contour = [x1, y1, ..., xn, yn]\n",
    "#             contour = contour.flatten()\n",
    "#             if len(contour) > 4:\n",
    "#                 segmentation.append(contour.tolist())\n",
    "        \n",
    "#         # obj class from truth matching\n",
    "#         obj_class = seg_truth_mapping.get(s, (2, {}))[0]  # 2 if no matching truth\n",
    "#         obj_info = seg_truth_mapping.get(s, (2, {}))[1]\n",
    "\n",
    "#         # skip if no valid contours or no matching truth\n",
    "#         if len(segmentation) == 0 or obj_class == 2:\n",
    "#             continue\n",
    "        \n",
    "#         obj = {\n",
    "#             \"bbox\": [int(x0), int(y0), w, h],\n",
    "#             \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "#             \"area\": w * h,\n",
    "#             \"segmentation\": segmentation,\n",
    "#             \"category_id\": obj_class,\n",
    "#             \"obj_id\": int(s),\n",
    "#             \"mag_F184\": obj_info['mag_F184'],\n",
    "#             \"mag_H158\": obj_info['mag_H158'],\n",
    "#             \"mag_J129\": obj_info['mag_J129'],\n",
    "#             \"mag_Y106\": obj_info['mag_Y106'],\n",
    "#             \"ra\": obj_info['ra'],\n",
    "#             \"dec\": obj_info['dec'],\n",
    "#             \"sep_arcsec\": obj_info[\"sep_arcsec\"],\n",
    "#             \"n_competing_dets\": obj_info[\"n_competing_dets\"],\n",
    "#             \"match_quality\": obj_info[\"match_quality\"]\n",
    "#         }\n",
    "#         anns.append(obj)\n",
    "    \n",
    "#     height, width = seg_cutout_data.shape\n",
    "    \n",
    "#     metadata = {\n",
    "#         \"annotations\": anns,\n",
    "#         'height': height,\n",
    "#         'width': width,\n",
    "#         \"image_id\": cutout_id,\n",
    "#     }\n",
    "    \n",
    "#     return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a42af5bb-fa3e-42c2-97af-891118195d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(seg_cutout_data, cutout_id, seg_truth_mapping):\n",
    "    \"\"\"\n",
    "    Optimized version of get_metadata with vectorization\n",
    "    Create metadata in the correct format for DeepDisc with annotations for matched detected objs in cutout\n",
    "    \"\"\"\n",
    "    anns = []\n",
    "    \n",
    "    # unique objs (vectorized)\n",
    "    unique_objs = np.unique(seg_cutout_data)\n",
    "    unique_objs = unique_objs[unique_objs > 0]  # removes background\n",
    "    \n",
    "    height, width = seg_cutout_data.shape\n",
    "    \n",
    "    for s in unique_objs:\n",
    "        # skip if no truth mapping\n",
    "        if s not in seg_truth_mapping:\n",
    "            continue\n",
    "        # obj class and info from truth matching\n",
    "        obj_class = seg_truth_mapping[s][0]\n",
    "        obj_info = seg_truth_mapping[s][1]\n",
    "        \n",
    "        # skip if no matching truth (class 2)\n",
    "        if obj_class == 2:\n",
    "            continue\n",
    "        # using boolean indexing directly avoiding np.where\n",
    "        # convert boolean arr (True -> 1 and False -> 0) using .astype\n",
    "        mask = (seg_cutout_data == s).astype(np.uint8)\n",
    "        \n",
    "        y_coords, x_coords = np.where(mask)\n",
    "        if len(y_coords) == 0:\n",
    "            continue\n",
    "            \n",
    "        x0, x1 = x_coords.min(), x_coords.max()\n",
    "        y0, y1 = y_coords.min(), y_coords.max()\n",
    "        w, h = int(x1 - x0), int(y1 - y0)\n",
    "        \n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        segmentation = []\n",
    "        for contour in contours:\n",
    "            contour = contour.flatten()\n",
    "            if len(contour) > 4:\n",
    "                segmentation.append(contour.tolist())\n",
    "        \n",
    "        if len(segmentation) == 0:\n",
    "            continue\n",
    "        \n",
    "        obj = {\n",
    "            \"bbox\": [int(x0), int(y0), w, h],\n",
    "            \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "            \"area\": w * h,\n",
    "            \"segmentation\": segmentation,\n",
    "            \"category_id\": obj_class,\n",
    "            \"obj_id\": int(s),\n",
    "            \"mag_F184\": obj_info['mag_F184'],\n",
    "            \"mag_H158\": obj_info['mag_H158'],\n",
    "            \"mag_J129\": obj_info['mag_J129'],\n",
    "            \"mag_Y106\": obj_info['mag_Y106'],\n",
    "            \"ra\": obj_info['ra'],\n",
    "            \"dec\": obj_info['dec'],\n",
    "            \"sep_arcsec\": obj_info[\"sep_arcsec\"],\n",
    "            \"n_competing_dets\": obj_info[\"n_competing_dets\"],\n",
    "            \"match_quality\": obj_info[\"match_quality\"]\n",
    "        }\n",
    "        anns.append(obj)\n",
    "    \n",
    "    return {\n",
    "        \"annotations\": anns,\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "        \"image_id\": cutout_id,\n",
    "    }\n",
    "\n",
    "\n",
    "def create_cutout_metadata(seg_cutouts, det_dfs, truth_dfs, ra_dec):\n",
    "    \"\"\"\n",
    "    Create comprehensive metadata for each cutout using det and truth catalog for cross-matching\n",
    "    \"\"\"\n",
    "    print(f\"\\nCreating metadata for {len(seg_cutouts)} cutouts...\")\n",
    "    \n",
    "    all_metadata = []\n",
    "    \n",
    "    for cutout_id, (seg_cutout, det_df, truth_df) in enumerate(\n",
    "        zip(seg_cutouts, det_dfs, truth_dfs)):\n",
    "#         print(f\"Cutout ID: {cutout_id}\")\n",
    "        matched_file = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/matched_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "        matched_objs, seg_truth_mapping = cross_match_objects(det_df, truth_df)\n",
    "        matched_objs.to_json(matched_file, orient='records')\n",
    "        \n",
    "        # metadata with annotations\n",
    "        cutout_metadata = get_metadata(seg_cutout.data, cutout_id, seg_truth_mapping)\n",
    "        cutout_metadata[\"file_name\"] = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/full_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.npy'\n",
    "        cutout_metadata[\"wcs\"] = seg_cutout.wcs.to_header_string()\n",
    "        cutout_metadata[\"det_cat_path\"] = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/det_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "        cutout_metadata[\"truth_cat_path\"] = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/truth_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "        cutout_metadata[\"matched_det_path\"] = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/matched_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "        cutout_metadata[\"num_matched\"] = len(matched_objs)\n",
    "        cutout_metadata[\"num_dets\"] = len(det_df)\n",
    "        cutout_metadata[\"num_truth\"] = len(truth_df)\n",
    "\n",
    "        all_metadata.append(cutout_metadata)\n",
    "    \n",
    "    \n",
    "    os.makedirs('./roman_data/annotations', exist_ok=True)\n",
    "    metadata_filename = f\"./roman_data/annotations/{ra_dec[0]}_{ra_dec[1]}.json\"    \n",
    "    convert_to_json(all_metadata, metadata_filename)\n",
    "    \n",
    "    print(f\"Metadata saved to {metadata_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b5059e-4ac2-43a5-a226-e0b9aca7f49d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bdefc05-de31-4fef-92d9-227d7419a930",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 14 tiles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Tiles:   0%|          | 0/14 [00:00<?, ?tile/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing tile 1/14: 50.93_-42.0\n",
      "==================================================\n",
      "Multiband coadd for 50.93_-42.0 has already been created!\n",
      "Time Multiband coadd: 0.29s\n",
      "Creating cutouts for 50.93_-42.0...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 2.99s\n",
      "\n",
      "Truth catalog loaded: 33334 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 32016\n",
      "  Non-empty cutouts: 225\n",
      "  Avg num of truth objects per non-empty cutout: 142.3\n",
      "Time Truth catalog processing: 2.05s\n",
      "\n",
      "Detection catalog loaded: 18909 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 14399\n",
      "  Non-empty cutouts: 225\n",
      "  Avg num of det objects per non-empty cutout: 64.0\n",
      "Time  Detection catalog processing: 4.53s\n",
      "\n",
      "Creating metadata for 225 cutouts...\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 9: matched by 2 detections\n",
      " Separation for det 51 : 0.0385 arcsec\n",
      " Separation for det 52 : 0.0269 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 10: matched by 2 detections\n",
      " Separation for det 59 : 0.0297 arcsec\n",
      " Separation for det 61 : 0.0398 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/50.93_-42.0.json' ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Tiles:   0%|          | 0/14 [00:47<?, ?tile/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved to ./roman_data/annotations/50.93_-42.0.json\n",
      "Time  Metadata creation: 37.74s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.29s (  0.6%)\n",
      "   Create cutouts:          2.99s (  6.3%)\n",
      "   Truth processing:        2.05s (  4.3%)\n",
      "   Detection processing:    4.53s (  9.5%)\n",
      "   Metadata creation:      37.74s ( 79.1%)\n",
      "   TOTAL TILE TIME:        47.69s\n",
      "\n",
      "üèÅ PROCESSING COMPLETE\n",
      "   Total time: 47.70s (0.8m)\n",
      "   Tiles processed: 1\n",
      "   Remaining tiles: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "detection_dir = 'roman_data/detection_fits'\n",
    "segmentation_dir = 'roman_data/segmentation_fits'\n",
    "truth_dir = 'roman_data/truth_fits'\n",
    "# the specific tilenames we want \n",
    "det_files = ['roman_data/detection_fits/dc2_det_50.93_-42.0.fits.gz','roman_data/detection_fits/dc2_det_51.34_-41.3.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_51.37_-38.3.fits.gz','roman_data/detection_fits/dc2_det_51.53_-40.0.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_52.31_-41.6.fits.gz','roman_data/detection_fits/dc2_det_52.93_-40.8.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_53.25_-41.8.fits.gz','roman_data/detection_fits/dc2_det_53.75_-38.9.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_54.24_-38.3.fits.gz','roman_data/detection_fits/dc2_det_54.31_-41.6.fits.gz',\n",
    "             'roman_data/detection_fits/dc2_det_55.03_-41.9.fits.gz','roman_data/detection_fits/dc2_det_56.06_-39.8.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_50.93_-38.8.fits.gz', 'roman_data/detection_fits/dc2_det_52.49_-39.1.fits.gz'] \n",
    "\n",
    "total_start_time = time.time()\n",
    "print(f\"Processing {len(det_files)} tiles...\")\n",
    "\n",
    "for i, det_file in enumerate(tqdm(det_files, desc=\"Processing Tiles\", unit=\"tile\")):\n",
    "#     if i == 0:\n",
    "#         continue\n",
    "    tile_start_time = time.time()\n",
    "    ra_dec = extract_ra_dec(det_file)\n",
    "    os.makedirs(f'roman_data/truth/{ra_dec[0]}_{ra_dec[1]}', exist_ok=True)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing tile {i+1}/{len(det_files)}: {ra_dec[0]}_{ra_dec[1]}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    # Step 1: Multiband Coadd\n",
    "    step_start = time.time()\n",
    "    full_img_data, w = create_multiband_coadd(ra_dec)\n",
    "    coadd_time = time.time() - step_start\n",
    "    print(f\"Time Multiband coadd: {coadd_time:.2f}s\")\n",
    "    \n",
    "    # Step 2: Creating Cutouts\n",
    "    step_start = time.time()\n",
    "    seg_file = f'{segmentation_dir}/dc2_seg_{ra_dec[0]}_{ra_dec[1]}.fits.gz'\n",
    "    truth_file = f'{truth_dir}/dc2_index_{ra_dec[0]}_{ra_dec[1]}.fits.gz'\n",
    "    seg_cutouts = create_cutouts(seg_file, full_img_data, ra_dec, w) # took ~ 4 minutes just to make all the cutouts for each tile\n",
    "    cutouts_time = time.time() - step_start\n",
    "    print(f\"Time Create cutouts: {cutouts_time:.2f}s\")\n",
    "    \n",
    "    # Step 3: Load and process truth cat\n",
    "    step_start = time.time()\n",
    "    # now, we get the truth catalog information for every cutout in this tile\n",
    "    truth = fits.open(truth_file)\n",
    "    truth_df = Table.read(truth,hdu=1).to_pandas()\n",
    "    truth.close()\n",
    "    print(f\"\\nTruth catalog loaded: {len(truth_df)} objects\")\n",
    "    cutout_truth_filenames, cutout_truth_dfs = get_cutout_truth_cat(seg_cutouts, truth_df, ra_dec)\n",
    "    truth_processing_time = time.time() - step_start\n",
    "    print(f\"Time Truth catalog processing: {truth_processing_time:.2f}s\")\n",
    "    \n",
    "    # Step 4: Load and process det cat\n",
    "    # now, we get the detection catalog info for every cutout in this tile\n",
    "    step_start = time.time()\n",
    "    det = fits.open(det_file)\n",
    "    det_df = Table.read(det, hdu=1).to_pandas()\n",
    "    det.close()\n",
    "    print(f\"\\nDetection catalog loaded: {len(det_df)} objects\")\n",
    "    cutout_det_filenames, cutout_det_dfs = get_cutout_det_cat(seg_cutouts, det_df, ra_dec)\n",
    "    det_processing_time = time.time() - step_start\n",
    "    print(f\"Time  Detection catalog processing: {det_processing_time:.2f}s\")\n",
    "    \n",
    "    # Step 5: Metadata and Annotations\n",
    "    step_start = time.time()\n",
    "    # now we need to create the DeepDISC annotations from the matched detections and metadata\n",
    "    create_cutout_metadata(seg_cutouts, cutout_det_dfs, cutout_truth_dfs, ra_dec)\n",
    "    metadata_time = time.time() - step_start\n",
    "    print(f\"Time  Metadata creation: {metadata_time:.2f}s\")\n",
    "    \n",
    "    del full_img_data, seg_cutouts, truth_df, det_df\n",
    "    del cutout_truth_dfs, cutout_det_dfs\n",
    "    gc.collect()\n",
    "    \n",
    "    tile_total_time = time.time() - tile_start_time\n",
    "    print(f\"\\nTILE SUMMARY:\")\n",
    "    print(f\"   Multiband coadd:     {coadd_time:>8.2f}s ({coadd_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   Create cutouts:      {cutouts_time:>8.2f}s ({cutouts_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   Truth processing:    {truth_processing_time:>8.2f}s ({truth_processing_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   Detection processing:{det_processing_time:>8.2f}s ({det_processing_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   Metadata creation:   {metadata_time:>8.2f}s ({metadata_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   TOTAL TILE TIME:     {tile_total_time:>8.2f}s\")\n",
    "    \n",
    "    if i > 0:\n",
    "        elapsed_total = time.time() - total_start_time\n",
    "        avg_time_per_tile = elapsed_total / (i + 1)\n",
    "        remaining_tiles = len(det_files) - (i + 1)\n",
    "        estimated_remaining = avg_time_per_tile * remaining_tiles\n",
    "        print(f\"   üìà Avg per tile:      {avg_time_per_tile:>8.2f}s\")\n",
    "        print(f\"   ‚è≥ Est. remaining:    {estimated_remaining/60:>8.1f}m ({estimated_remaining/3600:>5.1f}h)\")\n",
    "        \n",
    "    break\n",
    "\n",
    "total_elapsed = time.time() - total_start_time\n",
    "print(f\"\\nüèÅ PROCESSING COMPLETE\")\n",
    "print(f\"   Total time: {total_elapsed:.2f}s ({total_elapsed/60:.1f}m)\")\n",
    "print(f\"   Tiles processed: {min(i+1, len(det_files))}\")\n",
    "if i+1 < len(det_files):\n",
    "    print(f\"   Remaining tiles: {len(det_files) - (i+1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aeb333-7b4a-4255-bee8-cb61d5df029c",
   "metadata": {},
   "source": [
    "Output (**~76.75s (1.3m) for a single tile**):\n",
    "```\n",
    "Processing 14 tiles...\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "Processing Tiles:   0%|          | 0/14 [00:00<?, ?tile/s]\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "==================================================\n",
    "Processing tile 1/14: 50.93_-42.0\n",
    "==================================================\n",
    "Multiband coadd for 50.93_-42.0 has already been created!\n",
    "Time Multiband coadd: 0.45s\n",
    "Creating cutouts for 50.93_-42.0...\n",
    "Image size: 8825x8825\n",
    "Usable region: 7825x7825 (starting at 500,500)\n",
    "Cutouts: 15x15 = 225 total\n",
    "Spacing: x=522, y=522\n",
    "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
    "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
    "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
    "Created 225 cutouts\n",
    "Time Create cutouts: 17.51s\n",
    "\n",
    "Truth catalog loaded: 33334 objects\n",
    "Completed truth catalog processing for 225 cutouts\n",
    "  Total truth objects assigned: 32016\n",
    "  Non-empty cutouts: 225\n",
    "  Avg num of truth objects per non-empty cutout: 142.3\n",
    "Time Truth catalog processing: 3.01s\n",
    "\n",
    "Detection catalog loaded: 18909 objects\n",
    "Completed det catalog processing for 225 cutouts\n",
    "  Total det objects assigned: 14399\n",
    "  Non-empty cutouts: 225\n",
    "  Avg num of det objects per non-empty cutout: 64.0\n",
    "Time  Detection catalog processing: 4.66s\n",
    "\n",
    "Creating metadata for 225 cutouts...\n",
    "Found 1 truth objects matched by multiple detections:\n",
    "  Truth index 9: matched by 2 detections\n",
    " Separation for det 51 : 0.0385 arcsec\n",
    " Separation for det 52 : 0.0269 arcsec\n",
    "Found 1 truth objects matched by multiple detections:\n",
    "  Truth index 10: matched by 2 detections\n",
    " Separation for det 59 : 0.0297 arcsec\n",
    " Separation for det 61 : 0.0398 arcsec\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "WARNING:deepdisc.data_format.conversions:Using previously cached COCO format annotations at './roman_data/annotations/50.93_-42.0.json'. You need to clear the cache file if your dataset has been modified.\n",
    "Processing Tiles:   0%|          | 0/14 [01:16<?, ?tile/s]\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "Metadata saved to ./roman_data/annotations/50.93_-42.0.json\n",
    "Time  Metadata creation: 50.96s\n",
    "\n",
    "TILE SUMMARY:\n",
    "   Multiband coadd:         0.45s (  0.6%)\n",
    "   Create cutouts:         17.51s ( 22.8%)\n",
    "   Truth processing:        3.01s (  3.9%)\n",
    "   Detection processing:    4.66s (  6.1%)\n",
    "   Metadata creation:      50.96s ( 66.4%)\n",
    "   TOTAL TILE TIME:        76.75s\n",
    "\n",
    "üèÅ PROCESSING COMPLETE\n",
    "   Total time: 76.75s (1.3m)\n",
    "   Tiles processed: 1\n",
    "   Remaining tiles: 13\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7accdef-540c-4a04-b41d-a4efdde16911",
   "metadata": {},
   "source": [
    "~1.3 minutes for a single tile means ~20 minutes for 16 tiles. But, notice that each cutout is processed independently of the others. There are no dependencies between cutouts, so we can process multiple cutouts at the same time without worrying about race conditions or shared state. This is known as an \"embarrassingly parallel\" problem, which is ideal for multiprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f0cf20-8d3b-4f18-9659-3f87024c162b",
   "metadata": {},
   "source": [
    "# Adding Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f394f7-b2d0-4744-a745-be33d3641e19",
   "metadata": {},
   "source": [
    "## Helper and Parallel Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "979d0ff6-5696-4e9b-842d-c6657692acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_cutout(args):\n",
    "    \"\"\"Just process a single cutout\"\"\"\n",
    "    cutout_id, seg_cutout_data, det_df, truth_df, ra_dec, seg_cutout_wcs = args\n",
    "\n",
    "    matched_objs, seg_truth_mapping = cross_match_objects(det_df, truth_df)\n",
    " \n",
    "    metadata = get_metadata(seg_cutout_data, cutout_id, seg_truth_mapping)\n",
    "    metadata[\"file_name\"] = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/full_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.npy'\n",
    "    metadata[\"wcs\"] = seg_cutout_wcs\n",
    "    metadata[\"det_cat_path\"] = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/det_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "    metadata[\"truth_cat_path\"] = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/truth_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "    metadata[\"matched_det_path\"] = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/matched_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "    metadata[\"num_matched\"] = len(matched_objs)\n",
    "    metadata[\"num_dets\"] = len(det_df)\n",
    "    metadata[\"num_truth\"] = len(truth_df)\n",
    "    \n",
    "    return {\n",
    "        'cutout_id': cutout_id,\n",
    "        'metadata': metadata,\n",
    "        'matched_objs': matched_objs,\n",
    "        'success': True\n",
    "    }\n",
    "\n",
    "def create_cutout_metadata_parallel(seg_cutouts, det_dfs, truth_dfs, ra_dec, n_workers=6):\n",
    "    \"\"\"Parallel version with 16 workers\"\"\"\n",
    "    \n",
    "    print(f\"Creating metadata for {len(seg_cutouts)} cutouts using {n_workers} workers...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # prep args for parallel processing\n",
    "    args_list = []\n",
    "    for cutout_id, (seg_cutout, det_df, truth_df) in enumerate(zip(seg_cutouts, det_dfs, truth_dfs)):\n",
    "        args_list.append((\n",
    "            cutout_id,\n",
    "            seg_cutout.data,  # Pass data, not obj (for pickling)\n",
    "            det_df,\n",
    "            truth_df,\n",
    "            ra_dec,\n",
    "            seg_cutout.wcs.to_header_string()\n",
    "        ))\n",
    "    \n",
    "    all_metadata = []\n",
    "    successful_cutouts = 0\n",
    "    failed_cutouts = 0\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "        # submit all tasks\n",
    "        future_to_cutout = {\n",
    "            executor.submit(process_single_cutout, args): args[0] \n",
    "            for args in args_list\n",
    "        }\n",
    "        # collect results with progress tracking\n",
    "        for future in tqdm(as_completed(future_to_cutout), \n",
    "                          total=len(args_list), \n",
    "                          desc=\"Processing cutouts\",\n",
    "                          leave=False):\n",
    "            \n",
    "            cutout_id = future_to_cutout[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                \n",
    "                if result['success']:\n",
    "                    all_metadata.append(result['metadata'])\n",
    "                    \n",
    "                    # save matched objects\n",
    "                    matched_file = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/matched_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "                    result['matched_objs'].to_json(matched_file, orient='records')\n",
    "                    successful_cutouts += 1\n",
    "                else:\n",
    "                    print(f\"Failed cutout {cutout_id}: {result['error']}\")\n",
    "                    failed_cutouts += 1\n",
    "                    \n",
    "            except Exception as exc:\n",
    "                print(f'Cutout {cutout_id} generated an exception: {exc}')\n",
    "                failed_cutouts += 1\n",
    "    \n",
    "    # sort metadata by image_id to maintain order\n",
    "    all_metadata.sort(key=lambda x: x['image_id'])\n",
    "    \n",
    "    os.makedirs('./roman_data/annotations', exist_ok=True)\n",
    "    metadata_filename = f\"./roman_data/annotations/{ra_dec[0]}_{ra_dec[1]}.json\"\n",
    "    convert_to_json(all_metadata, metadata_filename)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Metadata creation completed in {elapsed_time:.2f}s\")\n",
    "    print(f\"Successfully processed {successful_cutouts}/{len(seg_cutouts)} cutouts\")\n",
    "    if failed_cutouts > 0:\n",
    "        print(f\"Failed cutouts: {failed_cutouts}\")\n",
    "    \n",
    "    print(f\"Metadata saved to {metadata_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47161178-72cd-44da-ae3a-02e6bba98522",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main using Multiprocessing (Submit this whole script as a job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ed7822-8e7f-4cd7-afe5-8ac029d40225",
   "metadata": {},
   "source": [
    "The below cell **DOES NOT work well on JupyterLab (atleast on the HAL Computing Cluster)**.\n",
    "\n",
    "Please refer to the full script under the section [Multiprocessing Script](#Multiprocessing-Script-to-Submit-to-Queue) or the file `prepare_roman_data.py` and submit a job to the queue to utilize a large number of workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f334bce5-1ca3-4ce2-8dae-2b73caaebb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_dir = 'roman_data/detection_fits'\n",
    "segmentation_dir = 'roman_data/segmentation_fits'\n",
    "truth_dir = 'roman_data/truth_fits'\n",
    "# the specific tilenames we want \n",
    "det_files = ['roman_data/detection_fits/dc2_det_50.93_-42.0.fits.gz','roman_data/detection_fits/dc2_det_51.34_-41.3.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_51.37_-38.3.fits.gz','roman_data/detection_fits/dc2_det_51.53_-40.0.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_52.31_-41.6.fits.gz','roman_data/detection_fits/dc2_det_52.93_-40.8.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_53.25_-41.8.fits.gz','roman_data/detection_fits/dc2_det_53.75_-38.9.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_54.24_-38.3.fits.gz','roman_data/detection_fits/dc2_det_54.31_-41.6.fits.gz',\n",
    "             'roman_data/detection_fits/dc2_det_55.03_-41.9.fits.gz','roman_data/detection_fits/dc2_det_56.06_-39.8.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_50.93_-38.8.fits.gz', 'roman_data/detection_fits/dc2_det_52.49_-39.1.fits.gz'] \n",
    "\n",
    "total_start_time = time.time()\n",
    "print(f\"Processing {len(det_files)} tiles...\")\n",
    "\n",
    "for i, det_file in enumerate(tqdm(det_files, desc=\"Processing Tiles\", unit=\"tile\")):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    tile_start_time = time.time()\n",
    "    ra_dec = extract_ra_dec(det_file)\n",
    "    os.makedirs(f'roman_data/truth/{ra_dec[0]}_{ra_dec[1]}', exist_ok=True)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing tile {i+1}/{len(det_files)}: {ra_dec[0]}_{ra_dec[1]}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    # Step 1: Multiband Coadd\n",
    "    step_start = time.time()\n",
    "    full_img_data, w = create_multiband_coadd(ra_dec)\n",
    "    coadd_time = time.time() - step_start\n",
    "    print(f\"Time Multiband coadd: {coadd_time:.2f}s\")\n",
    "    \n",
    "    # Step 2: Creating Cutouts\n",
    "    step_start = time.time()\n",
    "    seg_file = f'{segmentation_dir}/dc2_seg_{ra_dec[0]}_{ra_dec[1]}.fits.gz'\n",
    "    truth_file = f'{truth_dir}/dc2_index_{ra_dec[0]}_{ra_dec[1]}.fits.gz'\n",
    "    seg_cutouts = create_cutouts(seg_file, full_img_data, ra_dec, w) # took ~ 4 minutes just to make all the cutouts for each tile\n",
    "    cutouts_time = time.time() - step_start\n",
    "    print(f\"Time Create cutouts: {cutouts_time:.2f}s\")\n",
    "    \n",
    "    # Step 3: Load and process truth cat\n",
    "    step_start = time.time()\n",
    "    # now, we get the truth catalog information for every cutout in this tile\n",
    "    truth = fits.open(truth_file)\n",
    "    truth_df = Table.read(truth,hdu=1).to_pandas()\n",
    "    truth.close()\n",
    "    print(f\"\\nTruth catalog loaded: {len(truth_df)} objects\")\n",
    "    cutout_truth_filenames, cutout_truth_dfs = get_cutout_truth_cat(seg_cutouts, truth_df, ra_dec)\n",
    "    truth_processing_time = time.time() - step_start\n",
    "    print(f\"Time Truth catalog processing: {truth_processing_time:.2f}s\")\n",
    "    \n",
    "    # Step 4: Load and process det cat\n",
    "    # now, we get the detection catalog info for every cutout in this tile\n",
    "    step_start = time.time()\n",
    "    det = fits.open(det_file)\n",
    "    det_df = Table.read(det, hdu=1).to_pandas()\n",
    "    det.close()\n",
    "    print(f\"\\nDetection catalog loaded: {len(det_df)} objects\")\n",
    "    cutout_det_filenames, cutout_det_dfs = get_cutout_det_cat(seg_cutouts, det_df, ra_dec)\n",
    "    det_processing_time = time.time() - step_start\n",
    "    print(f\"Time  Detection catalog processing: {det_processing_time:.2f}s\")\n",
    "    \n",
    "    # Step 5: Metadata and Annotations\n",
    "    step_start = time.time()\n",
    "    # now we need to create the DeepDISC annotations from the matched detections and metadata\n",
    "    create_cutout_metadata_parallel(seg_cutouts, cutout_det_dfs, cutout_truth_dfs, ra_dec)\n",
    "    metadata_time = time.time() - step_start\n",
    "    print(f\"Time  Metadata creation: {metadata_time:.2f}s\")\n",
    "    \n",
    "    del full_img_data, seg_cutouts, truth_df, det_df\n",
    "    del cutout_truth_dfs, cutout_det_dfs\n",
    "    gc.collect()\n",
    "    \n",
    "    tile_total_time = time.time() - tile_start_time\n",
    "    print(f\"\\nTILE SUMMARY:\")\n",
    "    print(f\"   Multiband coadd:     {coadd_time:>8.2f}s ({coadd_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   Create cutouts:      {cutouts_time:>8.2f}s ({cutouts_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   Truth processing:    {truth_processing_time:>8.2f}s ({truth_processing_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   Detection processing:{det_processing_time:>8.2f}s ({det_processing_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   Metadata creation:   {metadata_time:>8.2f}s ({metadata_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   TOTAL TILE TIME:     {tile_total_time:>8.2f}s\")\n",
    "    \n",
    "    if i > 0:\n",
    "        elapsed_total = time.time() - total_start_time\n",
    "        avg_time_per_tile = elapsed_total / (i + 1)\n",
    "        remaining_tiles = len(det_files) - (i + 1)\n",
    "        estimated_remaining = avg_time_per_tile * remaining_tiles\n",
    "        print(f\"   üìà Avg per tile:      {avg_time_per_tile:>8.2f}s\")\n",
    "        print(f\"   ‚è≥ Est. remaining:    {estimated_remaining/60:>8.1f}m ({estimated_remaining/3600:>5.1f}h)\")\n",
    "    \n",
    "    speedup = 76.75 / tile_total_time\n",
    "    print(f\"   SPEEDUP:             {speedup:.1f}x faster than baseline\")\n",
    "    \n",
    "    break\n",
    "\n",
    "total_elapsed = time.time() - total_start_time\n",
    "print(f\"\\nüèÅ PROCESSING COMPLETE\")\n",
    "print(f\"   Total time: {total_elapsed:.2f}s ({total_elapsed/60:.1f}m)\")\n",
    "print(f\"   Tiles processed: {min(i+1, len(det_files))}\")\n",
    "if i+1 < len(det_files):\n",
    "    print(f\"   Remaining tiles: {len(det_files) - (i+1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891daeba-73d0-40b8-9548-fa7150fc2c77",
   "metadata": {},
   "source": [
    "# Multiprocessing Script to Submit to Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ec1a3-479e-4c48-9d0c-0ac7fe5d766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, cv2, time, gc\n",
    "import warnings\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from urllib.parse import urljoin\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.table import Table\n",
    "from astropy.wcs import WCS\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "from detectron2.structures import BoxMode\n",
    "from deepdisc.data_format.conversions import convert_to_json\n",
    "\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def extract_ra_dec(filename):\n",
    "    matches = re.search(r'dc2_(det|seg|index)_(\\d+\\.\\d+)_(\\-\\d+\\.\\d+)', filename)\n",
    "    if matches:\n",
    "        return matches.group(2), matches.group(3)\n",
    "    return None\n",
    "\n",
    "def create_multiband_coadd(ra_dec):\n",
    "    target_file = f\"roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/full_{ra_dec[0]}_{ra_dec[1]}.npy\"\n",
    "    # we still load in f184_img so we can grab the wcs\n",
    "    f184_img = fits.open(f'roman_data/original_fits/{ra_dec[0]}_{ra_dec[1]}/F184_{ra_dec[0]}_{ra_dec[1]}.fits')\n",
    "    w = WCS(f184_img[1].header)\n",
    "    if os.path.exists(target_file):\n",
    "        print(f\"Multiband coadd for {ra_dec[0]}_{ra_dec[1]} has already been created!\")\n",
    "        full_img_data = np.load(target_file)\n",
    "        return full_img_data, w\n",
    "    h158_img = fits.open(f'roman_data/original_fits/{ra_dec[0]}_{ra_dec[1]}/H158_{ra_dec[0]}_{ra_dec[1]}.fits')\n",
    "    y106_img = fits.open(f'roman_data/original_fits/{ra_dec[0]}_{ra_dec[1]}/Y106_{ra_dec[0]}_{ra_dec[1]}.fits')\n",
    "    j129_img = fits.open(f'roman_data/original_fits/{ra_dec[0]}_{ra_dec[1]}/J129_{ra_dec[0]}_{ra_dec[1]}.fits')\n",
    "    full_img_data = np.stack((f184_img[1].data, h158_img[1].data, y106_img[1].data, j129_img[1].data))\n",
    "    \n",
    "    np.save(target_file, full_img_data)    \n",
    "    \n",
    "    f184_img.close()\n",
    "    h158_img.close()\n",
    "    y106_img.close()\n",
    "    j129_img.close()\n",
    "    \n",
    "    print(f\"Multiband coadd saved to {target_file}\")\n",
    "    return full_img_data, w\n",
    "\n",
    "def create_cutouts(seg_file, full_img_data, ra_dec, w):\n",
    "    seg = fits.open(seg_file)\n",
    "    cutout_size = 512\n",
    "    overlap_pixels = 500\n",
    "    coadd_size = seg[0].data.shape\n",
    "    # only use the core region avoiding 500px overlap on each edge\n",
    "    usable_width = coadd_size[1] - 2 * overlap_pixels  # 7825\n",
    "    usable_height = coadd_size[0] - 2 * overlap_pixels  # 7825\n",
    "    start_x, start_y = overlap_pixels, overlap_pixels  # 500, 500\n",
    "    \n",
    "    nx_cutouts = usable_width // cutout_size\n",
    "    ny_cutouts = usable_height // cutout_size\n",
    "        \n",
    "    # calc spacing to distribute cutouts evenly\n",
    "    if nx_cutouts > 1:\n",
    "        x_spacing = (usable_width - cutout_size) // (nx_cutouts - 1)\n",
    "    else:\n",
    "        x_spacing = 0\n",
    "\n",
    "    if ny_cutouts > 1:\n",
    "        y_spacing = (usable_height - cutout_size) // (ny_cutouts - 1)\n",
    "    else:\n",
    "        y_spacing = 0\n",
    "    \n",
    "    print(f\"Creating cutouts for {ra_dec[0]}_{ra_dec[1]}...\")\n",
    "    print(f\"Image size: {coadd_size[1]}x{coadd_size[0]}\")\n",
    "    print(f\"Usable region: {usable_width}x{usable_height} (starting at {start_x},{start_y})\")\n",
    "    print(f\"Cutouts: {nx_cutouts}x{ny_cutouts} = {nx_cutouts * ny_cutouts} total\")\n",
    "    print(f\"Spacing: x={x_spacing}, y={y_spacing}\")\n",
    "    \n",
    "    counter = 0\n",
    "    seg_cutouts = []\n",
    "    for i in range(ny_cutouts):\n",
    "        for j in range(nx_cutouts):\n",
    "           # cutout center pos\n",
    "            if ny_cutouts == 1:\n",
    "                y_center = start_y + cutout_size // 2\n",
    "            else:\n",
    "                y_center = start_y + cutout_size // 2 + i * y_spacing\n",
    "            \n",
    "            if nx_cutouts == 1:\n",
    "                x_center = start_x + cutout_size // 2\n",
    "            else:\n",
    "                x_center = start_x + cutout_size // 2 + j * x_spacing\n",
    "            \n",
    "            seg_cutout = Cutout2D(seg[0].data, position=(x_center, y_center), \n",
    "                                size=cutout_size, wcs=w, mode='partial', fill_value=0)\n",
    "            seg_cutouts.append(seg_cutout)\n",
    "            \n",
    "            full_cutout_path = f'roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/full_c{counter}_{ra_dec[0]}_{ra_dec[1]}.npy'\n",
    "            if not os.path.exists(full_cutout_path):\n",
    "                raw_cutout_f184 = Cutout2D(full_img_data[0], position=(x_center, y_center), \n",
    "                                         size=cutout_size, wcs=w, mode='partial', fill_value=0)\n",
    "                raw_cutout_h158 = Cutout2D(full_img_data[1], position=(x_center, y_center), \n",
    "                                         size=cutout_size, wcs=w, mode='partial', fill_value=0)\n",
    "                raw_cutout_y106 = Cutout2D(full_img_data[2], position=(x_center, y_center), \n",
    "                                         size=cutout_size, wcs=w, mode='partial', fill_value=0)\n",
    "                raw_cutout_j129 = Cutout2D(full_img_data[3], position=(x_center, y_center), \n",
    "                                         size=cutout_size, wcs=w, mode='partial', fill_value=0)\n",
    "                full_raw_cutout = np.stack((raw_cutout_f184.data, raw_cutout_h158.data, \n",
    "                                          raw_cutout_y106.data, raw_cutout_j129.data)) \n",
    "                np.save(full_cutout_path, full_raw_cutout)\n",
    "            \n",
    "            # debug info for first few cutouts\n",
    "            if counter < 3:\n",
    "                print(f\"  Cutout {counter}: center=({x_center}, {y_center}), \"\n",
    "                      f\"bbox=({x_center-cutout_size//2}, {y_center-cutout_size//2}, \"\n",
    "                      f\"{x_center+cutout_size//2}, {y_center+cutout_size//2})\")\n",
    "            \n",
    "            counter += 1\n",
    "    seg.close()\n",
    "    print(f\"Created {len(seg_cutouts)} cutouts\")\n",
    "    return seg_cutouts\n",
    "\n",
    "def get_cutout_truth_cat(seg_cutouts, truth_df, ra_dec, verbose=False):\n",
    "    \"\"\"\n",
    "    We obtain a subset of the truth catalog for each cutout by first converting the 4 corners of the 512x512 cutout to RAs/DECs and then\n",
    "    filtering the truth catalog to only objects within those RA/Dec ranges. For convience, we also convert the filtered objects' coordinates \n",
    "    to cutout pixel coords. If no objs in cutout, file still gets saved for consistency.   \n",
    "    \"\"\"\n",
    "    truth_coords = SkyCoord(ra=truth_df['ra'].values*u.degree, dec=truth_df['dec'].values*u.degree)\n",
    "    truth_ras = truth_coords.ra.degree\n",
    "    truth_decs = truth_coords.dec.degree\n",
    "    # 4 corners of the 512x512 cutout\n",
    "    corners_pix = np.array([\n",
    "        [0, 0],        # bottom left\n",
    "        [511, 0],      # bottom right  \n",
    "        [511, 511],    # top right\n",
    "        [0, 511]       # top left\n",
    "    ])\n",
    "    \n",
    "    cutout_truth_filenames = []\n",
    "    cutout_truths = []\n",
    "\n",
    "    for imgid, seg_cutout in enumerate(seg_cutouts):\n",
    "        truth_cutout_path = f'roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/truth_c{imgid}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "        if not os.path.exists(truth_cutout_path):\n",
    "            corners_world = seg_cutout.wcs.pixel_to_world(corners_pix[:, 0], corners_pix[:, 1])\n",
    "            corner_ras = [coord.ra.degree for coord in corners_world]\n",
    "            corner_decs = [coord.dec.degree for coord in corners_world]\n",
    "            ra_min = min(corner_ras)\n",
    "            ra_max = max(corner_ras)\n",
    "            dec_min = min(corner_decs)\n",
    "            dec_max = max(corner_decs)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Cutout {imgid} boundaries:\")\n",
    "                print(f\"  RA: {ra_min:.6f}¬∞ to {ra_max:.6f}¬∞ (span: {(ra_max-ra_min)*3600:.2f}\\\")\")\n",
    "                print(f\"  Dec: {dec_min:.6f}¬∞ to {dec_max:.6f}¬∞ (span: {(dec_max-dec_min)*3600:.2f}\\\")\")\n",
    "                break\n",
    "\n",
    "            ra_mask = (truth_ras >= ra_min) & (truth_ras <= ra_max)\n",
    "            dec_mask = (truth_decs >= dec_min) & (truth_decs <= dec_max)\n",
    "            within_bounds = ra_mask & dec_mask\n",
    "            if not np.any(within_bounds):\n",
    "                print(f\"No truth objects found within cutout {imgid}\")\n",
    "                cutout_truth = pd.DataFrame(columns=[\n",
    "                    *truth_df.columns,\n",
    "                    'cutout_x', 'cutout_y', 'cutout_id'\n",
    "                ])\n",
    "            else:\n",
    "                cutout_truth = truth_df[within_bounds].copy()\n",
    "\n",
    "                cutout_truth_coords = truth_coords[within_bounds]\n",
    "                pix_coords = seg_cutout.wcs.world_to_pixel(cutout_truth_coords)\n",
    "                cutout_truth['cutout_x'] = pix_coords[0]\n",
    "                cutout_truth['cutout_y'] = pix_coords[1]\n",
    "                cutout_truth['cutout_id'] = imgid\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"  Found {len(cutout_truth)} truth objects within cutout {imgid} boundaries\")\n",
    "                    print(f\"  Pixel coordinate ranges:\")\n",
    "                    print(f\"    X: {cutout_truth['cutout_x'].min():.2f} to {cutout_truth['cutout_x'].max():.2f}\")\n",
    "                    print(f\"    Y: {cutout_truth['cutout_y'].min():.2f} to {cutout_truth['cutout_y'].max():.2f}\")\n",
    "                    break\n",
    "\n",
    "            cutout_truth.to_json(truth_cutout_path, orient='records')\n",
    "        else:\n",
    "            cutout_truth = pd.read_json(truth_cutout_path)\n",
    "        \n",
    "        cutout_truth_filenames.append(truth_cutout_path)\n",
    "        cutout_truths.append(cutout_truth)\n",
    "        # break\n",
    "    \n",
    "    total_objects = sum(len(result) for result in cutout_truths)\n",
    "    non_empty_cutouts = sum(1 for result in cutout_truths if len(result) > 0)\n",
    "    empty_cutouts = len(cutout_truths) - non_empty_cutouts \n",
    "    empty_cutout_ids = [imgid for imgid, cutout_truth in enumerate(cutout_truths) if len(cutout_truth) == 0]\n",
    "\n",
    "    print(f\"Completed truth catalog processing for {len(seg_cutouts)} cutouts\")\n",
    "    print(f\"  Total truth objects assigned: {total_objects}\")\n",
    "    print(f\"  Non-empty cutouts: {non_empty_cutouts}\")\n",
    "    print(f\"  Empty cutouts: {empty_cutouts} ({empty_cutout_ids})\")\n",
    "    print(f\"  Avg num of truth objects per non-empty cutout: {total_objects/non_empty_cutouts if non_empty_cutouts > 0 else 0:.1f}\")\n",
    "   \n",
    "    return cutout_truth_filenames, cutout_truths\n",
    "\n",
    "def get_cutout_det_cat(seg_cutouts, det_df, ra_dec, verbose=False):\n",
    "    \"\"\"\n",
    "    We obtain a subset of the det catalog for each cutout from the segmentation map and indexing into the detection catalog with those ids\n",
    "    For convience, we also convert the det objects' coords to cutout pixel coords.\n",
    "    \"\"\"\n",
    "    cutout_det_filenames = []\n",
    "    cutout_dets = []\n",
    "    corners_pix = np.array([\n",
    "        [0, 0],        # bottom left\n",
    "        [511, 0],      # bottom right  \n",
    "        [511, 511],    # top right\n",
    "        [0, 511]       # top left\n",
    "    ])\n",
    "    for imgid, seg_cutout in enumerate(seg_cutouts):\n",
    "        det_cutout_path = f'roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/det_c{imgid}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "        if not os.path.exists(det_cutout_path):\n",
    "            # unique objs from segm cutout\n",
    "            seg_objs = []\n",
    "            seg_img_cut = seg_cutout.data\n",
    "            for s in np.unique(seg_img_cut):\n",
    "                if s == 0:  # background\n",
    "                    continue\n",
    "                seg_objs.append(s)\n",
    "            seg_objs = np.asarray(seg_objs)\n",
    "\n",
    "            if len(seg_objs) == 0:\n",
    "                print(f\"No detected objects in this cutout {imgid}\")\n",
    "                cutout_det = pd.DataFrame(columns=[\n",
    "                    *det_df.columns,\n",
    "                    'cutout_x', 'cutout_y', 'seg_id', 'cutout_id'\n",
    "                ])\n",
    "            else:\n",
    "                det_objs = det_df.iloc[seg_objs-1].copy()  # -1 because segmentation IDs are 1-indexed and we match to number col in det df\n",
    "                det_coords = SkyCoord(ra=det_objs['alphawin_j2000'].values*u.degree, \n",
    "                                     dec=det_objs['deltawin_j2000'].values*u.degree)\n",
    "                det_ras = det_coords.ra.degree\n",
    "                det_decs = det_coords.dec.degree\n",
    "\n",
    "                # now we further filter the det coords by ensuring that we only take the objects whose center ra/dec is within the cutout\n",
    "                # some objs are detected in the segmentation map but their center ra/dec is outside of the cutout so we choose to exclude\n",
    "                # these objects despite there being a mask for them since we want to stay consistent with the filtering for truth catalog\n",
    "                corners_world = seg_cutout.wcs.pixel_to_world(corners_pix[:, 0], corners_pix[:, 1])\n",
    "                corner_ras = [coord.ra.degree for coord in corners_world]\n",
    "                corner_decs = [coord.dec.degree for coord in corners_world]\n",
    "                ra_min = min(corner_ras)\n",
    "                ra_max = max(corner_ras)\n",
    "                dec_min = min(corner_decs)\n",
    "                dec_max = max(corner_decs)\n",
    "\n",
    "                ra_mask = (det_ras >= ra_min) & (det_ras <= ra_max)\n",
    "                dec_mask = (det_decs >= dec_min) & (det_decs <= dec_max)\n",
    "                within_bounds = ra_mask & dec_mask\n",
    "                if not np.any(within_bounds):\n",
    "                    print(f\"No det objects found within cutout {imgid} after filtering by cutout boundaries\")\n",
    "                    cutout_det = pd.DataFrame(columns=[\n",
    "                        *det_df.columns,\n",
    "                        'cutout_x', 'cutout_y', 'seg_id', 'cutout_id'\n",
    "                    ])\n",
    "                else:\n",
    "                    cutout_det = det_objs[within_bounds].copy()\n",
    "                    cutout_det_coords = det_coords[within_bounds]\n",
    "                    cutout_seg_objs = seg_objs[within_bounds]\n",
    "                    pix_coords = seg_cutout.wcs.world_to_pixel(cutout_det_coords)\n",
    "                    cutout_det['cutout_x'] = pix_coords[0]\n",
    "                    cutout_det['cutout_y'] = pix_coords[1]\n",
    "                    cutout_det['seg_id'] = cutout_seg_objs\n",
    "                    cutout_det['cutout_id'] = imgid\n",
    "            \n",
    "            cutout_det.to_json(det_cutout_path, orient='records')\n",
    "        else:\n",
    "            cutout_det = pd.read_json(det_cutout_path)\n",
    "            \n",
    "        cutout_det_filenames.append(det_cutout_path)\n",
    "        cutout_dets.append(cutout_det)\n",
    "#         break\n",
    "    total_objects = sum(len(result) for result in cutout_dets)\n",
    "    non_empty_cutouts = sum(1 for result in cutout_dets if len(result) > 0)\n",
    "    empty_cutouts = len(cutout_dets) - non_empty_cutouts\n",
    "    empty_cutout_ids = [imgid for imgid, cutout_det in enumerate(cutout_dets) if len(cutout_det) == 0]\n",
    "    \n",
    "    print(f\"Completed det catalog processing for {len(seg_cutouts)} cutouts\")\n",
    "    print(f\"  Total det objects assigned: {total_objects}\")\n",
    "    print(f\"  Non-empty cutouts: {non_empty_cutouts}\")\n",
    "    print(f\"  Empty cutouts: {empty_cutouts} ({empty_cutout_ids})\")\n",
    "    print(f\"  Avg num of det objects per non-empty cutout: {total_objects/non_empty_cutouts if non_empty_cutouts > 0 else 0:.1f}\")\n",
    "    return cutout_det_filenames, cutout_dets\n",
    "\n",
    "def cross_match_objects(det_df, truth_df, max_sep_arcsec=0.0575):\n",
    "    \"\"\"\n",
    "    Cross-match detection catalog and truth catalog for a cutout\n",
    "    \"\"\"\n",
    "    if len(det_df) == 0 or len(truth_df) == 0:\n",
    "        return pd.DataFrame(), {}\n",
    "    \n",
    "    det_coords_np = np.column_stack([det_df['alphawin_j2000'].values, \n",
    "                                 det_df['deltawin_j2000'].values])\n",
    "    truth_coords_np = np.column_stack([truth_df['ra'].values, \n",
    "                                   truth_df['dec'].values])\n",
    "    # vectorized coord creation\n",
    "    det_coords = SkyCoord(ra=det_coords_np[:, 0]*u.degree, \n",
    "                            dec=det_coords_np[:, 1]*u.degree)\n",
    "    truth_coords = SkyCoord(ra=truth_coords_np[:, 0]*u.degree, \n",
    "                              dec=truth_coords_np[:, 1]*u.degree)\n",
    "    \n",
    "    # 0.0575 same as coadd pixel scale from https://academic.oup.com/mnras/article/522/2/2801/7076879?login=false\n",
    "    max_sep = max_sep_arcsec * u.arcsec\n",
    "    idx_truth, d2d, d3d = det_coords.match_to_catalog_sky(truth_coords)\n",
    "    sep_constraint = d2d <= max_sep\n",
    "    \n",
    "    if not np.any(sep_constraint):\n",
    "        print(f\"Detection catalog has objects but none of them match with the truth objects within {max_sep} arcsecs\")\n",
    "        return pd.DataFrame(), {}\n",
    "    \n",
    "    matched_objs = pd.DataFrame()\n",
    "    seg_truth_mapping = {}\n",
    "    \n",
    "    if np.any(sep_constraint):\n",
    "        matched_det_idxs = np.where(sep_constraint)[0]\n",
    "        matched_truth_idxs = idx_truth[sep_constraint]\n",
    "        matched_seps = d2d[sep_constraint]\n",
    "        \n",
    "        unique_truth_idxs, counts = np.unique(matched_truth_idxs, return_counts=True)\n",
    "        \n",
    "        duplicate_truth_idxs = unique_truth_idxs[counts > 1]\n",
    "        \n",
    "        if len(duplicate_truth_idxs) > 0:\n",
    "            print(f\"Found {len(duplicate_truth_idxs)} truth objects matched by multiple detections:\")\n",
    "            for truth_idx in duplicate_truth_idxs:\n",
    "                det_matches = matched_det_idxs[matched_truth_idxs == truth_idx]\n",
    "                seps = matched_seps[matched_truth_idxs == truth_idx]\n",
    "                print(f\"  Truth index {truth_idx}: matched by {len(det_matches)} detections\")\n",
    "                for i, sep in enumerate(seps.to(u.arcsec).value):\n",
    "                    print(f\" Separation for det {det_matches[i]} : {sep:.4f} arcsec\")\n",
    "        \n",
    "        final_det_idxs = []\n",
    "        final_truth_idxs = []\n",
    "        final_seps = []\n",
    "        n_competing_dets = []\n",
    "        match_quality_flags = []\n",
    "    \n",
    "        for truth_idx in unique_truth_idxs:\n",
    "            # all dets matching this truth obj\n",
    "            matching_det_mask = matched_truth_idxs == truth_idx\n",
    "            matching_det_idxs = matched_det_idxs[matching_det_mask]\n",
    "            matching_seps = matched_seps[matching_det_mask]\n",
    "            # how many dets competed for this truth obj\n",
    "            n_competitors = len(matching_det_idxs)\n",
    "\n",
    "            # keeping closest match\n",
    "            closest_idx = np.argmin(matching_seps)\n",
    "            chosen_det_idx = matching_det_idxs[closest_idx]\n",
    "            chosen_sep = matching_seps[closest_idx]\n",
    "\n",
    "            final_det_idxs.append(chosen_det_idx)\n",
    "            final_truth_idxs.append(truth_idx)\n",
    "            final_seps.append(chosen_sep.to(u.arcsec).value)\n",
    "            n_competing_dets.append(n_competitors)\n",
    "            if n_competitors == 1:\n",
    "                match_quality_flags.append('unique')\n",
    "            else:\n",
    "                match_quality_flags.append('closest_of_multiple')\n",
    "        \n",
    "        final_det_idxs = np.array(final_det_idxs)\n",
    "        final_truth_idxs = np.array(final_truth_idxs)\n",
    "        final_seps = np.array(final_seps)\n",
    "        n_competing_dets = np.array(n_competing_dets) \n",
    "        \n",
    "        matched_dets = det_df.iloc[final_det_idxs].copy().reset_index(drop=True)\n",
    "        matched_truths = truth_df.iloc[final_truth_idxs].copy().reset_index(drop=True)\n",
    "        \n",
    "        matched_objs = matched_dets.copy()\n",
    "        for col in matched_truths.columns:\n",
    "            if col not in ['cutout_id', 'cutout_x', 'cutout_y']:\n",
    "                matched_objs[f'{col}'] = matched_truths[col].values\n",
    "            elif col in ['cutout_x', 'cutout_y']:\n",
    "                matched_objs[f'truth_{col}'] = matched_truths[col].values\n",
    "            \n",
    "        matched_objs['sep_arcsec'] = [sep for sep in final_seps]\n",
    "        matched_objs['sep_pixels'] = matched_objs['sep_arcsec'] / 0.0575  # roman pixel scale\n",
    "        matched_objs['n_competing_dets'] = n_competing_dets\n",
    "        matched_objs['is_ambiguous_match'] = n_competing_dets > 1\n",
    "        matched_objs['match_quality'] = match_quality_flags\n",
    "        \n",
    "        # mapping seg ID to truth classification and other truth info\n",
    "        for i, (det_idx, truth_idx) in enumerate(zip(final_det_idxs, final_truth_idxs)):\n",
    "            seg_id = det_df.iloc[det_idx]['seg_id']\n",
    "            truth_row = truth_df.iloc[truth_idx]\n",
    "            seg_truth_mapping[seg_id] = (int(truth_row['gal_star']), {\n",
    "                \"mag_F184\": truth_row['mag_F184'],\n",
    "                \"mag_H158\": truth_row['mag_H158'],\n",
    "                \"mag_J129\": truth_row['mag_J129'],\n",
    "                \"mag_Y106\": truth_row['mag_Y106'],\n",
    "                \"ra\": truth_row['ra'],\n",
    "                \"dec\": truth_row['dec'],\n",
    "                \"sep_arcsec\": final_seps[i],\n",
    "                \"n_competing_dets\": int(n_competing_dets[i]),\n",
    "                \"match_quality\": match_quality_flags[i]\n",
    "            })\n",
    "    \n",
    "    n_unique = np.sum(np.array(match_quality_flags) == 'unique')\n",
    "    n_ambiguous = np.sum(np.array(match_quality_flags) == 'closest_of_multiple')\n",
    "    median_sep = np.median([sep for sep in final_seps])\n",
    "\n",
    "#     print(f\"Match quality summary:\")\n",
    "#     print(f\"  Unique matches: {n_unique}\")\n",
    "#     print(f\"  Ambiguous matches (closest selected): {n_ambiguous}\")\n",
    "#     print(f\"  Median separation: {median_sep:.4f} arcsec\")\n",
    "#     print(f\"  Max competing detections for single truth: {np.max(n_competing_dets)}\")\n",
    "    \n",
    "    return matched_objs, seg_truth_mapping\n",
    "\n",
    "def get_metadata(seg_cutout_data, cutout_id, seg_truth_mapping):\n",
    "    \"\"\"Optimized version of get_metadata with vectorization\"\"\"\n",
    "    anns = []\n",
    "    height, width = seg_cutout_data.shape\n",
    "    \n",
    "    if len(seg_truth_mapping) == 0:\n",
    "        print(f\"Cutout {cutout_id}: Empty seg truth mapping! No annotations\")\n",
    "    else:\n",
    "        # unique objs (vectorized)\n",
    "        unique_objs = np.unique(seg_cutout_data)\n",
    "        unique_objs = unique_objs[unique_objs > 0]  # removes background\n",
    "\n",
    "        for s in unique_objs:\n",
    "            # skip if no truth mapping\n",
    "            if s not in seg_truth_mapping:\n",
    "                continue\n",
    "            # obj class and info from truth matching\n",
    "            obj_class = seg_truth_mapping[s][0]\n",
    "            obj_info = seg_truth_mapping[s][1]\n",
    "\n",
    "            # skip if no matching truth (class 2)\n",
    "            if obj_class == 2:\n",
    "                continue\n",
    "            # using boolean indexing directly avoiding np.where\n",
    "            # convert boolean arr (True -> 1 and False -> 0) using .astype\n",
    "            mask = (seg_cutout_data == s).astype(np.uint8)\n",
    "\n",
    "            y_coords, x_coords = np.where(mask)\n",
    "            if len(y_coords) == 0:\n",
    "                continue\n",
    "\n",
    "            x0, x1 = x_coords.min(), x_coords.max()\n",
    "            y0, y1 = y_coords.min(), y_coords.max()\n",
    "            w, h = int(x1 - x0), int(y1 - y0)\n",
    "\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            segmentation = []\n",
    "            for contour in contours:\n",
    "                contour = contour.flatten()\n",
    "                if len(contour) > 4:\n",
    "                    segmentation.append(contour.tolist())\n",
    "\n",
    "            if len(segmentation) == 0:\n",
    "                continue\n",
    "\n",
    "            obj = {\n",
    "                \"bbox\": [int(x0), int(y0), w, h],\n",
    "                \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                \"area\": w * h,\n",
    "                \"segmentation\": segmentation,\n",
    "                \"category_id\": obj_class,\n",
    "                \"obj_id\": int(s),\n",
    "                \"mag_F184\": obj_info['mag_F184'],\n",
    "                \"mag_H158\": obj_info['mag_H158'],\n",
    "                \"mag_J129\": obj_info['mag_J129'],\n",
    "                \"mag_Y106\": obj_info['mag_Y106'],\n",
    "                \"ra\": obj_info['ra'],\n",
    "                \"dec\": obj_info['dec'],\n",
    "                \"sep_arcsec\": obj_info[\"sep_arcsec\"],\n",
    "                \"n_competing_dets\": obj_info[\"n_competing_dets\"],\n",
    "                \"match_quality\": obj_info[\"match_quality\"]\n",
    "            }\n",
    "            anns.append(obj)\n",
    "    \n",
    "    return {\n",
    "        \"annotations\": anns,\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "        \"image_id\": cutout_id,\n",
    "    }\n",
    "\n",
    "def process_single_cutout(args):\n",
    "    \"\"\"Just process a single cutout\"\"\"\n",
    "    cutout_id, seg_cutout_data, det_df, truth_df, ra_dec, seg_cutout_wcs = args\n",
    "    if len(det_df) == 0:\n",
    "        print(f\"Cutout {cutout_id}: Empty detection catalog\")\n",
    "    if len(truth_df) == 0:\n",
    "        print(f\"Cutout {cutout_id}: Empty truth catalog\")\n",
    "    matched_objs, seg_truth_mapping = cross_match_objects(det_df, truth_df)\n",
    " \n",
    "    metadata = get_metadata(seg_cutout_data, cutout_id, seg_truth_mapping)\n",
    "    metadata[\"file_name\"] = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/full_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.npy'\n",
    "    metadata[\"wcs\"] = seg_cutout_wcs\n",
    "    metadata[\"det_cat_path\"] = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/det_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "    metadata[\"truth_cat_path\"] = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/truth_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "    metadata[\"matched_det_path\"] = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/matched_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "    metadata[\"num_matched\"] = len(matched_objs)\n",
    "    metadata[\"num_dets\"] = len(det_df)\n",
    "    metadata[\"num_truth\"] = len(truth_df)\n",
    "    \n",
    "    return {\n",
    "        'cutout_id': cutout_id,\n",
    "        'metadata': metadata,\n",
    "        'matched_objs': matched_objs,\n",
    "        'success': True\n",
    "    }\n",
    "\n",
    "def create_cutout_metadata_parallel(seg_cutouts, det_dfs, truth_dfs, ra_dec, n_workers=64):\n",
    "    \"\"\"Parallel version with 16 workers\"\"\"\n",
    "    \n",
    "    print(f\"Creating metadata for {len(seg_cutouts)} cutouts using {n_workers} workers...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # prep args for parallel processing\n",
    "    args_list = []\n",
    "    for cutout_id, (seg_cutout, det_df, truth_df) in enumerate(zip(seg_cutouts, det_dfs, truth_dfs)):\n",
    "        args_list.append((\n",
    "            cutout_id,\n",
    "            seg_cutout.data,  # Pass data, not obj (for pickling)\n",
    "            det_df,\n",
    "            truth_df,\n",
    "            ra_dec,\n",
    "            seg_cutout.wcs.to_header_string()\n",
    "        ))\n",
    "    \n",
    "    all_metadata = []\n",
    "    successful_cutouts = 0\n",
    "    failed_cutouts = 0\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "        # submit all tasks\n",
    "        future_to_cutout = {\n",
    "            executor.submit(process_single_cutout, args): args[0] \n",
    "            for args in args_list\n",
    "        }\n",
    "        # collect results with progress tracking\n",
    "        for future in tqdm(as_completed(future_to_cutout), \n",
    "                          total=len(args_list), \n",
    "                          desc=\"Processing cutouts\",\n",
    "                          leave=False):\n",
    "            \n",
    "            cutout_id = future_to_cutout[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                \n",
    "                if result['success']:\n",
    "                    all_metadata.append(result['metadata'])\n",
    "                    \n",
    "                    # save matched objects\n",
    "                    matched_file = f'./roman_data/truth/{ra_dec[0]}_{ra_dec[1]}/matched_c{cutout_id}_{ra_dec[0]}_{ra_dec[1]}.json'\n",
    "                    result['matched_objs'].to_json(matched_file, orient='records')\n",
    "                    successful_cutouts += 1\n",
    "                else:\n",
    "                    print(f\"Failed cutout {cutout_id}: {result['error']}\")\n",
    "                    failed_cutouts += 1\n",
    "                    \n",
    "            except Exception as exc:\n",
    "                print(f'Cutout {cutout_id} generated an exception: {exc}')\n",
    "                failed_cutouts += 1\n",
    "    \n",
    "    # sort metadata by image_id to maintain order\n",
    "    all_metadata.sort(key=lambda x: x['image_id'])\n",
    "    \n",
    "    os.makedirs('./roman_data/annotations', exist_ok=True)\n",
    "    metadata_filename = f\"./roman_data/annotations/{ra_dec[0]}_{ra_dec[1]}.json\"\n",
    "    convert_to_json(all_metadata, metadata_filename)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Metadata creation completed in {elapsed_time:.2f}s\")\n",
    "    print(f\"Successfully processed {successful_cutouts}/{len(seg_cutouts)} cutouts\")\n",
    "    if failed_cutouts > 0:\n",
    "        print(f\"Failed cutouts: {failed_cutouts}\")\n",
    "    \n",
    "    print(f\"Metadata saved to {metadata_filename}\")\n",
    "\n",
    "detection_dir = 'roman_data/detection_fits'\n",
    "segmentation_dir = 'roman_data/segmentation_fits'\n",
    "truth_dir = 'roman_data/truth_fits'\n",
    "# the specific tilenames we want \n",
    "det_files = ['roman_data/detection_fits/dc2_det_50.93_-42.0.fits.gz','roman_data/detection_fits/dc2_det_51.34_-41.3.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_51.37_-38.3.fits.gz','roman_data/detection_fits/dc2_det_51.53_-40.0.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_52.31_-41.6.fits.gz','roman_data/detection_fits/dc2_det_52.93_-40.8.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_53.25_-41.8.fits.gz','roman_data/detection_fits/dc2_det_53.75_-38.9.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_54.24_-38.3.fits.gz','roman_data/detection_fits/dc2_det_54.31_-41.6.fits.gz',\n",
    "             'roman_data/detection_fits/dc2_det_55.03_-41.9.fits.gz','roman_data/detection_fits/dc2_det_56.06_-39.8.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_50.93_-38.8.fits.gz', 'roman_data/detection_fits/dc2_det_52.49_-39.1.fits.gz',\n",
    "            'roman_data/detection_fits/dc2_det_52.40_-41.1.fits.gz', 'roman_data/detection_fits/dc2_det_55.54_-41.9.fits.gz']\n",
    "\n",
    "# det_files = ['roman_data/detection_fits/dc2_det_52.40_-41.1.fits.gz']\n",
    "\n",
    "# det_files = ['roman_data/detection_fits/dc2_det_51.53_-40.0.fits.gz', 'roman_data/detection_fits/dc2_det_52.31_-41.6.fits.gz',\n",
    "#              'roman_data/detection_fits/dc2_det_52.93_-40.8.fits.gz',\n",
    "#             'roman_data/detection_fits/dc2_det_53.25_-41.8.fits.gz','roman_data/detection_fits/dc2_det_53.75_-38.9.fits.gz',\n",
    "#             'roman_data/detection_fits/dc2_det_54.24_-38.3.fits.gz','roman_data/detection_fits/dc2_det_54.31_-41.6.fits.gz',\n",
    "#              'roman_data/detection_fits/dc2_det_55.03_-41.9.fits.gz','roman_data/detection_fits/dc2_det_56.06_-39.8.fits.gz',\n",
    "#             'roman_data/detection_fits/dc2_det_50.93_-38.8.fits.gz', 'roman_data/detection_fits/dc2_det_52.49_-39.1.fits.gz']\n",
    "\n",
    "total_start_time = time.time()\n",
    "print(f\"Processing {len(det_files)} tiles...\")\n",
    "\n",
    "for i, det_file in enumerate(tqdm(det_files, desc=\"Processing Tiles\", unit=\"tile\")):\n",
    "#     if i == 0 or i == 1:\n",
    "#         continue\n",
    "    tile_start_time = time.time()\n",
    "    ra_dec = extract_ra_dec(det_file)\n",
    "    os.makedirs(f'roman_data/truth/{ra_dec[0]}_{ra_dec[1]}', exist_ok=True)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing tile {i+1}/{len(det_files)}: {ra_dec[0]}_{ra_dec[1]}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    # Step 1: Multiband Coadd\n",
    "    step_start = time.time()\n",
    "    full_img_data, w = create_multiband_coadd(ra_dec)\n",
    "    coadd_time = time.time() - step_start\n",
    "    print(f\"Time Multiband coadd: {coadd_time:.2f}s\")\n",
    "    \n",
    "    # Step 2: Creating Cutouts\n",
    "    step_start = time.time()\n",
    "    seg_file = f'{segmentation_dir}/dc2_seg_{ra_dec[0]}_{ra_dec[1]}.fits.gz'\n",
    "    truth_file = f'{truth_dir}/dc2_index_{ra_dec[0]}_{ra_dec[1]}.fits.gz'\n",
    "    seg_cutouts = create_cutouts(seg_file, full_img_data, ra_dec, w) # took ~ 4 minutes just to make all the cutouts for each tile\n",
    "    cutouts_time = time.time() - step_start\n",
    "    print(f\"Time Create cutouts: {cutouts_time:.2f}s\")\n",
    "    \n",
    "    # Step 3: Load and process truth cat\n",
    "    step_start = time.time()\n",
    "    # now, we get the truth catalog information for every cutout in this tile\n",
    "    truth = fits.open(truth_file)\n",
    "    truth_df = Table.read(truth,hdu=1).to_pandas()\n",
    "    truth.close()\n",
    "    print(f\"\\nTruth catalog loaded: {len(truth_df)} objects\")\n",
    "    cutout_truth_filenames, cutout_truth_dfs = get_cutout_truth_cat(seg_cutouts, truth_df, ra_dec)\n",
    "    truth_processing_time = time.time() - step_start\n",
    "    print(f\"Time Truth catalog processing: {truth_processing_time:.2f}s\")\n",
    "    \n",
    "    # Step 4: Load and process det cat\n",
    "    # now, we get the detection catalog info for every cutout in this tile\n",
    "    step_start = time.time()\n",
    "    det = fits.open(det_file)\n",
    "    det_df = Table.read(det, hdu=1).to_pandas()\n",
    "    det.close()\n",
    "    print(f\"\\nDetection catalog loaded: {len(det_df)} objects\")\n",
    "    cutout_det_filenames, cutout_det_dfs = get_cutout_det_cat(seg_cutouts, det_df, ra_dec)\n",
    "    det_processing_time = time.time() - step_start\n",
    "    print(f\"Time  Detection catalog processing: {det_processing_time:.2f}s\")\n",
    "    \n",
    "    # Step 5: Metadata and Annotations\n",
    "    step_start = time.time()\n",
    "    # now we need to create the DeepDISC annotations from the matched detections and metadata\n",
    "    create_cutout_metadata_parallel(seg_cutouts, cutout_det_dfs, cutout_truth_dfs, ra_dec)\n",
    "    metadata_time = time.time() - step_start\n",
    "    print(f\"Time  Metadata creation: {metadata_time:.2f}s\")\n",
    "    \n",
    "    del full_img_data, seg_cutouts, truth_df, det_df\n",
    "    del cutout_truth_dfs, cutout_det_dfs\n",
    "    gc.collect()\n",
    "    \n",
    "    tile_total_time = time.time() - tile_start_time\n",
    "    print(f\"\\nTILE SUMMARY:\")\n",
    "    print(f\"   Multiband coadd:     {coadd_time:>8.2f}s ({coadd_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   Create cutouts:      {cutouts_time:>8.2f}s ({cutouts_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   Truth processing:    {truth_processing_time:>8.2f}s ({truth_processing_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   Detection processing:{det_processing_time:>8.2f}s ({det_processing_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   Metadata creation:   {metadata_time:>8.2f}s ({metadata_time/tile_total_time*100:>5.1f}%)\")\n",
    "    print(f\"   TOTAL TILE TIME:     {tile_total_time:>8.2f}s\")\n",
    "    \n",
    "#     if i > 0:\n",
    "#         elapsed_total = time.time() - total_start_time\n",
    "#         avg_time_per_tile = elapsed_total / (i + 1)\n",
    "#         remaining_tiles = len(det_files) - (i + 1)\n",
    "#         estimated_remaining = avg_time_per_tile * remaining_tiles\n",
    "#         print(f\"   üìà Avg per tile:      {avg_time_per_tile:>8.2f}s\")\n",
    "#         print(f\"   ‚è≥ Est. remaining:    {estimated_remaining/60:>8.1f}m ({estimated_remaining/3600:>5.1f}h)\")\n",
    "    \n",
    "#     speedup = 76.75 / tile_total_time\n",
    "#     print(f\"   SPEEDUP:             {speedup:.1f}x faster than baseline\")\n",
    "    \n",
    "#     break\n",
    "\n",
    "total_elapsed = time.time() - total_start_time\n",
    "print(f\"\\nüèÅ PROCESSING COMPLETE\")\n",
    "print(f\"   Total time: {total_elapsed:.2f}s ({total_elapsed/60:.1f}m)\")\n",
    "print(f\"   Tiles processed: {min(i+1, len(det_files))}\")\n",
    "if i+1 < len(det_files):\n",
    "    print(f\"   Remaining tiles: {len(det_files) - (i+1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9467b3-ca85-47ce-9bd5-7baabfd7951d",
   "metadata": {},
   "source": [
    "## Job Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c796cef-7377-42e8-a035-aefbf7384793",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=\"prep_roman\"\n",
    "#SBATCH --output=\"prep_roman_out.%j.%N.out\"\n",
    "#SBATCH --error=\"prep_roman_err.%j.%N.err\"\n",
    "#SBATCH --partition=cpu\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=64\n",
    "#SBATCH --time=0:40:00\n",
    "\n",
    "module load conda_base\n",
    "conda activate deepdisc\n",
    "cd ~\n",
    "# python lsst_anns.py\n",
    "python prepare_roman_data.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b5343f-4f60-4bcb-8132-2613ccc0f7ed",
   "metadata": {},
   "source": [
    "## With 64 CPUs (~20-25s for a single tile) ~3x faster than serial!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc9d2e6-4fb5-44e5-ad8c-3b7819a38e6c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 16 tiles...\n",
      "\n",
      "==================================================\n",
      "Processing tile 1/16: 50.93_-42.0\n",
      "==================================================\n",
      "Multiband coadd for 50.93_-42.0 has already been created!\n",
      "Time Multiband coadd: 0.39s\n",
      "Creating cutouts for 50.93_-42.0...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 13.40s\n",
      "\n",
      "Truth catalog loaded: 33334 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 32016\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 142.3\n",
      "Time Truth catalog processing: 4.17s\n",
      "\n",
      "Detection catalog loaded: 18909 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 14399\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 64.0\n",
      "Time  Detection catalog processing: 5.52s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 10: matched by 2 detections\n",
      " Separation for det 59 : 0.0297 arcsec\n",
      " Separation for det 61 : 0.0398 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 9: matched by 2 detections\n",
      " Separation for det 51 : 0.0385 arcsec\n",
      " Separation for det 52 : 0.0269 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/50.93_-42.0.json' ...\n",
      "Metadata creation completed in 10.22s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/50.93_-42.0.json\n",
      "Time  Metadata creation: 10.23s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.39s (  1.2%)\n",
      "   Create cutouts:         13.40s ( 39.7%)\n",
      "   Truth processing:        4.17s ( 12.3%)\n",
      "   Detection processing:    5.52s ( 16.4%)\n",
      "   Metadata creation:      10.23s ( 30.3%)\n",
      "   TOTAL TILE TIME:        33.77s\n",
      "\n",
      "==================================================\n",
      "Processing tile 2/16: 51.34_-41.3\n",
      "==================================================\n",
      "Multiband coadd for 51.34_-41.3 has already been created!\n",
      "Time Multiband coadd: 0.26s\n",
      "Creating cutouts for 51.34_-41.3...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 9.20s\n",
      "\n",
      "Truth catalog loaded: 36758 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 35252\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 156.7\n",
      "Time Truth catalog processing: 3.77s\n",
      "\n",
      "Detection catalog loaded: 20528 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 15431\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 68.6\n",
      "Time  Detection catalog processing: 5.27s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 91: matched by 2 detections\n",
      " Separation for det 21 : 0.0517 arcsec\n",
      " Separation for det 22 : 0.0265 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/51.34_-41.3.json' ...\n",
      "Metadata creation completed in 11.53s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/51.34_-41.3.json\n",
      "Time  Metadata creation: 11.54s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.26s (  0.9%)\n",
      "   Create cutouts:          9.20s ( 30.6%)\n",
      "   Truth processing:        3.77s ( 12.5%)\n",
      "   Detection processing:    5.27s ( 17.5%)\n",
      "   Metadata creation:      11.54s ( 38.3%)\n",
      "   TOTAL TILE TIME:        30.10s\n",
      "\n",
      "==================================================\n",
      "Processing tile 3/16: 51.37_-38.3\n",
      "==================================================\n",
      "Multiband coadd for 51.37_-38.3 has already been created!\n",
      "Time Multiband coadd: 0.29s\n",
      "Creating cutouts for 51.37_-38.3...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 13.18s\n",
      "\n",
      "Truth catalog loaded: 34646 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 33272\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 147.9\n",
      "Time Truth catalog processing: 3.90s\n",
      "\n",
      "Detection catalog loaded: 20060 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 15373\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 68.3\n",
      "Time  Detection catalog processing: 5.38s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 33: matched by 2 detections\n",
      " Separation for det 42 : 0.0414 arcsec\n",
      " Separation for det 43 : 0.0359 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/51.37_-38.3.json' ...\n",
      "Metadata creation completed in 6.28s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/51.37_-38.3.json\n",
      "Time  Metadata creation: 6.29s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.29s (  1.0%)\n",
      "   Create cutouts:         13.18s ( 45.3%)\n",
      "   Truth processing:        3.90s ( 13.4%)\n",
      "   Detection processing:    5.38s ( 18.5%)\n",
      "   Metadata creation:       6.29s ( 21.6%)\n",
      "   TOTAL TILE TIME:        29.11s\n",
      "\n",
      "==================================================\n",
      "Processing tile 4/16: 51.53_-40.0\n",
      "==================================================\n",
      "Multiband coadd for 51.53_-40.0 has already been created!\n",
      "Time Multiband coadd: 0.33s\n",
      "Creating cutouts for 51.53_-40.0...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 10.81s\n",
      "\n",
      "Truth catalog loaded: 36431 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 34980\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 155.5\n",
      "Time Truth catalog processing: 4.27s\n",
      "\n",
      "Detection catalog loaded: 20266 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 15776\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 70.1\n",
      "Time  Detection catalog processing: 5.42s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 15: matched by 2 detections\n",
      " Separation for det 20 : 0.0399 arcsec\n",
      " Separation for det 21 : 0.0364 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 33: matched by 2 detections\n",
      " Separation for det 0 : 0.0482 arcsec\n",
      " Separation for det 1 : 0.0244 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/51.53_-40.0.json' ...\n",
      "Metadata creation completed in 6.34s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/51.53_-40.0.json\n",
      "Time  Metadata creation: 6.36s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.33s (  1.2%)\n",
      "   Create cutouts:         10.81s ( 39.7%)\n",
      "   Truth processing:        4.27s ( 15.7%)\n",
      "   Detection processing:    5.42s ( 19.9%)\n",
      "   Metadata creation:       6.36s ( 23.3%)\n",
      "   TOTAL TILE TIME:        27.25s\n",
      "\n",
      "==================================================\n",
      "Processing tile 5/16: 52.31_-41.6\n",
      "==================================================\n",
      "Multiband coadd for 52.31_-41.6 has already been created!\n",
      "Time Multiband coadd: 0.29s\n",
      "Creating cutouts for 52.31_-41.6...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 12.66s\n",
      "\n",
      "Truth catalog loaded: 33757 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 32469\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 144.3\n",
      "Time Truth catalog processing: 4.08s\n",
      "\n",
      "Detection catalog loaded: 19138 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 13939\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 62.0\n",
      "Time  Detection catalog processing: 5.43s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 35: matched by 2 detections\n",
      " Separation for det 38 : 0.0509 arcsec\n",
      " Separation for det 39 : 0.0230 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/52.31_-41.6.json' ...\n",
      "Metadata creation completed in 8.55s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/52.31_-41.6.json\n",
      "Time  Metadata creation: 8.56s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.29s (  0.9%)\n",
      "   Create cutouts:         12.66s ( 40.7%)\n",
      "   Truth processing:        4.08s ( 13.1%)\n",
      "   Detection processing:    5.43s ( 17.5%)\n",
      "   Metadata creation:       8.56s ( 27.5%)\n",
      "   TOTAL TILE TIME:        31.08s\n",
      "\n",
      "==================================================\n",
      "Processing tile 6/16: 52.93_-40.8\n",
      "==================================================\n",
      "Multiband coadd for 52.93_-40.8 has already been created!\n",
      "Time Multiband coadd: 0.22s\n",
      "Creating cutouts for 52.93_-40.8...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 8.40s\n",
      "\n",
      "Truth catalog loaded: 35604 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 34134\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 151.7\n",
      "Time Truth catalog processing: 3.76s\n",
      "\n",
      "Detection catalog loaded: 19735 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 14960\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 66.5\n",
      "Time  Detection catalog processing: 5.34s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 16: matched by 2 detections\n",
      " Separation for det 71 : 0.0254 arcsec\n",
      " Separation for det 72 : 0.0392 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 46: matched by 2 detections\n",
      " Separation for det 14 : 0.0497 arcsec\n",
      " Separation for det 15 : 0.0544 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 10: matched by 2 detections\n",
      " Separation for det 38 : 0.0433 arcsec\n",
      " Separation for det 39 : 0.0542 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/52.93_-40.8.json' ...\n",
      "Metadata creation completed in 8.16s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/52.93_-40.8.json\n",
      "Time  Metadata creation: 8.17s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.22s (  0.8%)\n",
      "   Create cutouts:          8.40s ( 32.4%)\n",
      "   Truth processing:        3.76s ( 14.5%)\n",
      "   Detection processing:    5.34s ( 20.6%)\n",
      "   Metadata creation:       8.17s ( 31.5%)\n",
      "   TOTAL TILE TIME:        25.95s\n",
      "\n",
      "==================================================\n",
      "Processing tile 7/16: 53.25_-41.8\n",
      "==================================================\n",
      "Multiband coadd for 53.25_-41.8 has already been created!\n",
      "Time Multiband coadd: 0.27s\n",
      "Creating cutouts for 53.25_-41.8...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 6.49s\n",
      "\n",
      "Truth catalog loaded: 33790 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 32458\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 144.3\n",
      "Time Truth catalog processing: 4.13s\n",
      "\n",
      "Detection catalog loaded: 18094 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 13707\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 60.9\n",
      "Time  Detection catalog processing: 5.58s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 19: matched by 2 detections\n",
      " Separation for det 50 : 0.0430 arcsec\n",
      " Separation for det 51 : 0.0045 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 41: matched by 2 detections\n",
      " Separation for det 6 : 0.0474 arcsec\n",
      " Separation for det 7 : 0.0353 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 64: matched by 2 detections\n",
      " Separation for det 20 : 0.0528 arcsec\n",
      " Separation for det 21 : 0.0300 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/53.25_-41.8.json' ...\n",
      "Metadata creation completed in 6.34s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/53.25_-41.8.json\n",
      "Time  Metadata creation: 6.35s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.27s (  1.2%)\n",
      "   Create cutouts:          6.49s ( 28.4%)\n",
      "   Truth processing:        4.13s ( 18.1%)\n",
      "   Detection processing:    5.58s ( 24.4%)\n",
      "   Metadata creation:       6.35s ( 27.8%)\n",
      "   TOTAL TILE TIME:        22.89s\n",
      "\n",
      "==================================================\n",
      "Processing tile 8/16: 53.75_-38.9\n",
      "==================================================\n",
      "Multiband coadd for 53.75_-38.9 has already been created!\n",
      "Time Multiband coadd: 0.26s\n",
      "Creating cutouts for 53.75_-38.9...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 8.52s\n",
      "\n",
      "Truth catalog loaded: 33443 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 32081\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 142.6\n",
      "Time Truth catalog processing: 3.89s\n",
      "\n",
      "Detection catalog loaded: 17902 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 13340\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 59.3\n",
      "Time  Detection catalog processing: 5.30s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Caching COCO format annotations at './roman_data/annotations/53.75_-38.9.json' ...\n",
      "Metadata creation completed in 7.36s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/53.75_-38.9.json\n",
      "Time  Metadata creation: 7.38s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.26s (  1.0%)\n",
      "   Create cutouts:          8.52s ( 33.5%)\n",
      "   Truth processing:        3.89s ( 15.3%)\n",
      "   Detection processing:    5.30s ( 20.9%)\n",
      "   Metadata creation:       7.38s ( 29.0%)\n",
      "   TOTAL TILE TIME:        25.41s\n",
      "\n",
      "==================================================\n",
      "Processing tile 9/16: 54.24_-38.3\n",
      "==================================================\n",
      "Multiband coadd for 54.24_-38.3 has already been created!\n",
      "Time Multiband coadd: 0.25s\n",
      "Creating cutouts for 54.24_-38.3...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 7.86s\n",
      "\n",
      "Truth catalog loaded: 32185 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 30913\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 137.4\n",
      "Time Truth catalog processing: 3.76s\n",
      "\n",
      "Detection catalog loaded: 16004 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 11928\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 53.0\n",
      "Time  Detection catalog processing: 5.17s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 25: matched by 2 detections\n",
      " Separation for det 40 : 0.0341 arcsec\n",
      " Separation for det 43 : 0.0511 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 6: matched by 2 detections\n",
      " Separation for det 91 : 0.0116 arcsec\n",
      " Separation for det 92 : 0.0520 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/54.24_-38.3.json' ...\n",
      "Metadata creation completed in 5.24s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/54.24_-38.3.json\n",
      "Time  Metadata creation: 5.25s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.25s (  1.1%)\n",
      "   Create cutouts:          7.86s ( 35.2%)\n",
      "   Truth processing:        3.76s ( 16.8%)\n",
      "   Detection processing:    5.17s ( 23.1%)\n",
      "   Metadata creation:       5.25s ( 23.5%)\n",
      "   TOTAL TILE TIME:        22.35s\n",
      "\n",
      "==================================================\n",
      "Processing tile 10/16: 54.31_-41.6\n",
      "==================================================\n",
      "Multiband coadd for 54.31_-41.6 has already been created!\n",
      "Time Multiband coadd: 0.32s\n",
      "Creating cutouts for 54.31_-41.6...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 10.03s\n",
      "\n",
      "Truth catalog loaded: 34025 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 32597\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 144.9\n",
      "Time Truth catalog processing: 4.17s\n",
      "\n",
      "Detection catalog loaded: 17878 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 13748\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 61.1\n",
      "Time  Detection catalog processing: 5.30s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 19: matched by 2 detections\n",
      " Separation for det 44 : 0.0260 arcsec\n",
      " Separation for det 45 : 0.0457 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/54.31_-41.6.json' ...\n",
      "Metadata creation completed in 4.98s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/54.31_-41.6.json\n",
      "Time  Metadata creation: 4.99s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.32s (  1.3%)\n",
      "   Create cutouts:         10.03s ( 40.3%)\n",
      "   Truth processing:        4.17s ( 16.8%)\n",
      "   Detection processing:    5.30s ( 21.3%)\n",
      "   Metadata creation:       4.99s ( 20.1%)\n",
      "   TOTAL TILE TIME:        24.88s\n",
      "\n",
      "==================================================\n",
      "Processing tile 11/16: 55.03_-41.9\n",
      "==================================================\n",
      "Multiband coadd for 55.03_-41.9 has already been created!\n",
      "Time Multiband coadd: 0.28s\n",
      "Creating cutouts for 55.03_-41.9...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 11.48s\n",
      "\n",
      "Truth catalog loaded: 34449 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 33008\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 146.7\n",
      "Time Truth catalog processing: 4.19s\n",
      "\n",
      "Detection catalog loaded: 24600 objects\n",
      "No detected objects in this cutout 55\n",
      "No detected objects in this cutout 56\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 20007\n",
      "  Non-empty cutouts: 223\n",
      "  Empty cutouts: 2 ([55, 56])\n",
      "  Avg num of det objects per non-empty cutout: 89.7\n",
      "Time  Detection catalog processing: 5.60s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Cutout 55: Empty detection catalog\n",
      "Cutout 55: Empty seg truth mapping! No annotations\n",
      "Cutout 56: Empty detection catalog\n",
      "Cutout 56: Empty seg truth mapping! No annotations\n",
      "Detection catalog has objects but none of them match with the truth objects within 0.0575 arcsec arcsecs\n",
      "Cutout 70: Empty seg truth mapping! No annotations\n",
      "Detection catalog has objects but none of them match with the truth objects within 0.0575 arcsec arcsecs\n",
      "Cutout 71: Empty seg truth mapping! No annotations\n",
      "Caching COCO format annotations at './roman_data/annotations/55.03_-41.9.json' ...\n",
      "Metadata creation completed in 5.61s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/55.03_-41.9.json\n",
      "Time  Metadata creation: 5.62s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.28s (  1.0%)\n",
      "   Create cutouts:         11.48s ( 42.2%)\n",
      "   Truth processing:        4.19s ( 15.4%)\n",
      "   Detection processing:    5.60s ( 20.6%)\n",
      "   Metadata creation:       5.62s ( 20.6%)\n",
      "   TOTAL TILE TIME:        27.22s\n",
      "\n",
      "==================================================\n",
      "Processing tile 12/16: 56.06_-39.8\n",
      "==================================================\n",
      "Multiband coadd for 56.06_-39.8 has already been created!\n",
      "Time Multiband coadd: 0.29s\n",
      "Creating cutouts for 56.06_-39.8...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 13.35s\n",
      "\n",
      "Truth catalog loaded: 34148 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 32770\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 145.6\n",
      "Time Truth catalog processing: 4.13s\n",
      "\n",
      "Detection catalog loaded: 18362 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 13679\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 60.8\n",
      "Time  Detection catalog processing: 5.38s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 2: matched by 2 detections\n",
      " Separation for det 72 : 0.0415 arcsec\n",
      " Separation for det 76 : 0.0462 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 33: matched by 2 detections\n",
      " Separation for det 10 : 0.0234 arcsec\n",
      " Separation for det 11 : 0.0236 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 7: matched by 2 detections\n",
      " Separation for det 41 : 0.0555 arcsec\n",
      " Separation for det 42 : 0.0514 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 90: matched by 3 detections\n",
      " Separation for det 57 : 0.0175 arcsec\n",
      " Separation for det 58 : 0.0177 arcsec\n",
      " Separation for det 59 : 0.0509 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/56.06_-39.8.json' ...\n",
      "Metadata creation completed in 6.33s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/56.06_-39.8.json\n",
      "Time  Metadata creation: 6.34s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.29s (  1.0%)\n",
      "   Create cutouts:         13.35s ( 45.2%)\n",
      "   Truth processing:        4.13s ( 14.0%)\n",
      "   Detection processing:    5.38s ( 18.2%)\n",
      "   Metadata creation:       6.34s ( 21.5%)\n",
      "   TOTAL TILE TIME:        29.56s\n",
      "\n",
      "==================================================\n",
      "Processing tile 13/16: 50.93_-38.8\n",
      "==================================================\n",
      "Multiband coadd for 50.93_-38.8 has already been created!\n",
      "Time Multiband coadd: 0.24s\n",
      "Creating cutouts for 50.93_-38.8...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 10.71s\n",
      "\n",
      "Truth catalog loaded: 34378 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 33064\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 147.0\n",
      "Time Truth catalog processing: 3.85s\n",
      "\n",
      "Detection catalog loaded: 21382 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 16281\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 72.4\n",
      "Time  Detection catalog processing: 5.24s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Detection catalog has objects but none of them match with the truth objects within 0.0575 arcsec arcsecs\n",
      "Cutout 24: Empty seg truth mapping! No annotations\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 7: matched by 2 detections\n",
      " Separation for det 0 : 0.0256 arcsec\n",
      " Separation for det 6 : 0.0273 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 1: matched by 2 detections\n",
      " Separation for det 75 : 0.0219 arcsec\n",
      " Separation for det 76 : 0.0544 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/50.93_-38.8.json' ...\n",
      "Metadata creation completed in 5.28s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/50.93_-38.8.json\n",
      "Time  Metadata creation: 5.29s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.24s (  0.9%)\n",
      "   Create cutouts:         10.71s ( 42.2%)\n",
      "   Truth processing:        3.85s ( 15.2%)\n",
      "   Detection processing:    5.24s ( 20.6%)\n",
      "   Metadata creation:       5.29s ( 20.9%)\n",
      "   TOTAL TILE TIME:        25.39s\n",
      "\n",
      "==================================================\n",
      "Processing tile 14/16: 52.49_-39.1\n",
      "==================================================\n",
      "Multiband coadd for 52.49_-39.1 has already been created!\n",
      "Time Multiband coadd: 0.29s\n",
      "Creating cutouts for 52.49_-39.1...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 10.52s\n",
      "\n",
      "Truth catalog loaded: 34879 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 33451\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 148.7\n",
      "Time Truth catalog processing: 4.31s\n",
      "\n",
      "Detection catalog loaded: 18862 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 14103\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 62.7\n",
      "Time  Detection catalog processing: 5.59s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 23: matched by 2 detections\n",
      " Separation for det 32 : 0.0425 arcsec\n",
      " Separation for det 35 : 0.0491 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 16: matched by 2 detections\n",
      " Separation for det 12 : 0.0552 arcsec\n",
      " Separation for det 13 : 0.0548 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 78: matched by 2 detections\n",
      " Separation for det 14 : 0.0562 arcsec\n",
      " Separation for det 15 : 0.0321 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/52.49_-39.1.json' ...\n",
      "Metadata creation completed in 5.72s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/52.49_-39.1.json\n",
      "Time  Metadata creation: 5.74s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.29s (  1.1%)\n",
      "   Create cutouts:         10.52s ( 39.7%)\n",
      "   Truth processing:        4.31s ( 16.2%)\n",
      "   Detection processing:    5.59s ( 21.1%)\n",
      "   Metadata creation:       5.74s ( 21.6%)\n",
      "   TOTAL TILE TIME:        26.51s\n",
      "\n",
      "==================================================\n",
      "Processing tile 15/16: 52.40_-41.1\n",
      "==================================================\n",
      "Multiband coadd for 52.40_-41.1 has already been created!\n",
      "Time Multiband coadd: 0.24s\n",
      "Creating cutouts for 52.40_-41.1...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 11.08s\n",
      "\n",
      "Truth catalog loaded: 34258 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 32863\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 146.1\n",
      "Time Truth catalog processing: 4.09s\n",
      "\n",
      "Detection catalog loaded: 19100 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 14528\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 64.6\n",
      "Time  Detection catalog processing: 5.34s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 53: matched by 2 detections\n",
      " Separation for det 59 : 0.0356 arcsec\n",
      " Separation for det 61 : 0.0461 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/52.40_-41.1.json' ...\n",
      "Metadata creation completed in 5.81s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/52.40_-41.1.json\n",
      "Time  Metadata creation: 5.82s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         0.24s (  0.9%)\n",
      "   Create cutouts:         11.08s ( 41.6%)\n",
      "   Truth processing:        4.09s ( 15.3%)\n",
      "   Detection processing:    5.34s ( 20.1%)\n",
      "   Metadata creation:       5.82s ( 21.9%)\n",
      "   TOTAL TILE TIME:        26.64s\n",
      "\n",
      "==================================================\n",
      "Processing tile 16/16: 55.54_-41.9\n",
      "==================================================\n",
      "Multiband coadd saved to roman_data/truth/55.54_-41.9/full_55.54_-41.9.npy\n",
      "Time Multiband coadd: 1.21s\n",
      "Creating cutouts for 55.54_-41.9...\n",
      "Image size: 8825x8825\n",
      "Usable region: 7825x7825 (starting at 500,500)\n",
      "Cutouts: 15x15 = 225 total\n",
      "Spacing: x=522, y=522\n",
      "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
      "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
      "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
      "Created 225 cutouts\n",
      "Time Create cutouts: 7.73s\n",
      "\n",
      "Truth catalog loaded: 33160 objects\n",
      "Completed truth catalog processing for 225 cutouts\n",
      "  Total truth objects assigned: 31831\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of truth objects per non-empty cutout: 141.5\n",
      "Time Truth catalog processing: 2.83s\n",
      "\n",
      "Detection catalog loaded: 17799 objects\n",
      "Completed det catalog processing for 225 cutouts\n",
      "  Total det objects assigned: 13238\n",
      "  Non-empty cutouts: 225\n",
      "  Empty cutouts: 0 ([])\n",
      "  Avg num of det objects per non-empty cutout: 58.8\n",
      "Time  Detection catalog processing: 4.13s\n",
      "Creating metadata for 225 cutouts using 64 workers...\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 3: matched by 2 detections\n",
      " Separation for det 5 : 0.0453 arcsec\n",
      " Separation for det 6 : 0.0556 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 83: matched by 2 detections\n",
      " Separation for det 48 : 0.0275 arcsec\n",
      " Separation for det 51 : 0.0300 arcsec\n",
      "Found 1 truth objects matched by multiple detections:\n",
      "  Truth index 23: matched by 2 detections\n",
      " Separation for det 1 : 0.0351 arcsec\n",
      " Separation for det 2 : 0.0231 arcsec\n",
      "Caching COCO format annotations at './roman_data/annotations/55.54_-41.9.json' ...\n",
      "Metadata creation completed in 5.10s\n",
      "Successfully processed 225/225 cutouts\n",
      "Metadata saved to ./roman_data/annotations/55.54_-41.9.json\n",
      "Time  Metadata creation: 5.12s\n",
      "\n",
      "TILE SUMMARY:\n",
      "   Multiband coadd:         1.21s (  5.8%)\n",
      "   Create cutouts:          7.73s ( 36.7%)\n",
      "   Truth processing:        2.83s ( 13.4%)\n",
      "   Detection processing:    4.13s ( 19.6%)\n",
      "   Metadata creation:       5.12s ( 24.3%)\n",
      "   TOTAL TILE TIME:        21.08s\n",
      "\n",
      "üèÅ PROCESSING COMPLETE\n",
      "   Total time: 429.20s (7.2m)\n",
      "   Tiles processed: 16\n"
     ]
    }
   ],
   "source": [
    "!cat /home/yse2/ondemand/data/sys/myjobs/projects/default/1/prep_roman_out.210868.hal13.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f1a771-1bde-4aee-b70a-3f92e845ab69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## With 64 CPUs (~27.42s for a single tile) ~3x faster than serial!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06295574-eb03-41bf-a92b-85fccd699878",
   "metadata": {},
   "source": [
    "```\n",
    "Processing 14 tiles...\n",
    "\n",
    "==================================================\n",
    "Processing tile 3/14: 51.37_-38.3\n",
    "==================================================\n",
    "Multiband coadd for 51.37_-38.3 has already been created!\n",
    "Time Multiband coadd: 0.28s\n",
    "Creating cutouts for 51.37_-38.3...\n",
    "Image size: 8825x8825\n",
    "Usable region: 7825x7825 (starting at 500,500)\n",
    "Cutouts: 15x15 = 225 total\n",
    "Spacing: x=522, y=522\n",
    "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
    "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
    "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
    "Created 225 cutouts\n",
    "Time Create cutouts: 8.21s\n",
    "\n",
    "Truth catalog loaded: 34646 objects\n",
    "Completed truth catalog processing for 225 cutouts\n",
    "  Total truth objects assigned: 33272\n",
    "  Non-empty cutouts: 225\n",
    "  Avg num of truth objects per non-empty cutout: 147.9\n",
    "Time Truth catalog processing: 2.82s\n",
    "\n",
    "Detection catalog loaded: 20060 objects\n",
    "Completed det catalog processing for 225 cutouts\n",
    "  Total det objects assigned: 15373\n",
    "  Non-empty cutouts: 225\n",
    "  Avg num of det objects per non-empty cutout: 68.3\n",
    "Time  Detection catalog processing: 4.20s\n",
    "Creating metadata for 225 cutouts using 64 workers...\n",
    "Found 1 truth objects matched by multiple detections:\n",
    "  Truth index 33: matched by 2 detections\n",
    " Separation for det 42 : 0.0414 arcsec\n",
    " Separation for det 43 : 0.0359 arcsec\n",
    "Caching COCO format annotations at './roman_data/annotations/51.37_-38.3.json' ...\n",
    "Metadata creation completed in 11.85s\n",
    "Successfully processed 225/225 cutouts\n",
    "Metadata saved to ./roman_data/annotations/51.37_-38.3.json\n",
    "Time  Metadata creation: 11.87s\n",
    "\n",
    "TILE SUMMARY:\n",
    "   Multiband coadd:         0.28s (  1.0%)\n",
    "   Create cutouts:          8.21s ( 29.9%)\n",
    "   Truth processing:        2.82s ( 10.3%)\n",
    "   Detection processing:    4.20s ( 15.3%)\n",
    "   Metadata creation:      11.87s ( 43.3%)\n",
    "   TOTAL TILE TIME:        27.42s\n",
    "   üìà Avg per tile:          9.14s\n",
    "   ‚è≥ Est. remaining:         1.7m (  0.0h)\n",
    "   SPEEDUP:             2.8x faster than baseline\n",
    "\n",
    "üèÅ PROCESSING COMPLETE\n",
    "   Total time: 27.42s (0.5m)\n",
    "   Tiles processed: 3\n",
    "   Remaining tiles: 11\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6098bd-3c47-4328-8f87-832ca5e3bd36",
   "metadata": {
    "tags": []
   },
   "source": [
    "## With 32 CPUs (~16.6s for a single tile given cutouts and truth/det catalogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d408dc1c-88d2-4f80-93f3-5cd851367a11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "```\n",
    "Processing 14 tiles...\n",
    "\n",
    "==================================================\n",
    "Processing tile 2/14: 51.34_-41.3\n",
    "==================================================\n",
    "Multiband coadd for 51.34_-41.3 has already been created!\n",
    "Time Multiband coadd: 0.37s\n",
    "Creating cutouts for 51.34_-41.3...\n",
    "Image size: 8825x8825\n",
    "Usable region: 7825x7825 (starting at 500,500)\n",
    "Cutouts: 15x15 = 225 total\n",
    "Spacing: x=522, y=522\n",
    "  Cutout 0: center=(756, 756), bbox=(500, 500, 1012, 1012)\n",
    "  Cutout 1: center=(1278, 756), bbox=(1022, 500, 1534, 1012)\n",
    "  Cutout 2: center=(1800, 756), bbox=(1544, 500, 2056, 1012)\n",
    "Created 225 cutouts\n",
    "Time Create cutouts: 2.98s\n",
    "\n",
    "Truth catalog loaded: 36758 objects\n",
    "Completed truth catalog processing for 225 cutouts\n",
    "  Total truth objects assigned: 35252\n",
    "  Non-empty cutouts: 225\n",
    "  Avg num of truth objects per non-empty cutout: 156.7\n",
    "Time Truth catalog processing: 2.07s\n",
    "\n",
    "Detection catalog loaded: 20528 objects\n",
    "Completed det catalog processing for 225 cutouts\n",
    "  Total det objects assigned: 15431\n",
    "  Non-empty cutouts: 225\n",
    "  Avg num of det objects per non-empty cutout: 68.6\n",
    "Time  Detection catalog processing: 4.53s\n",
    "Creating metadata for 225 cutouts using 32 workers...\n",
    "Found 1 truth objects matched by multiple detections:\n",
    "  Truth index 91: matched by 2 detections\n",
    " Separation for det 21 : 0.0517 arcsec\n",
    " Separation for det 22 : 0.0265 arcsec\n",
    "Caching COCO format annotations at './roman_data/annotations/51.34_-41.3.json' ...\n",
    "Metadata creation completed in 6.14s\n",
    "Successfully processed 225/225 cutouts\n",
    "Metadata saved to ./roman_data/annotations/51.34_-41.3.json\n",
    "Time  Metadata creation: 6.15s\n",
    "\n",
    "TILE SUMMARY:\n",
    "   Multiband coadd:         0.37s (  2.3%)\n",
    "   Create cutouts:          2.98s ( 18.4%)\n",
    "   Truth processing:        2.07s ( 12.8%)\n",
    "   Detection processing:    4.53s ( 28.1%)\n",
    "   Metadata creation:       6.15s ( 38.1%)\n",
    "   TOTAL TILE TIME:        16.16s\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-deepdisc]",
   "language": "python",
   "name": "conda-env-.conda-deepdisc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
